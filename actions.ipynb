{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import requests\n",
    "from rasa_core_sdk import Action\n",
    "from rasa_core_sdk.events import SlotSet\n",
    "\n",
    "class GetTodayHoroscope(Action):\n",
    "    \n",
    "    def name(self):\n",
    "        return \"get_todays_horoscope\"\n",
    "    \n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        # type: (Dispatcher, DialogueStateTracker, Domain) -> List[Event]\n",
    "        \n",
    "        user_horoscope_sign = tracker.get_slot('horoscope_sign')\n",
    "        base_url = \"http://horoscope-api.herokuapp.com/horoscope/{day}/{sign}\"\n",
    "        url = base_url.format(**{'day': \"today\", 'sign': user_horoscope_sign})\n",
    "        #http://horoscope-api.herokuapp.com/horoscope/today/capricorn\n",
    "        res = requests.get(url)\n",
    "        todays_horoscope = res.json()['horoscope']\n",
    "        response = \"Your today's horoscope:\\n{}\".format(todays_horoscope)\n",
    "        \n",
    "        dispatcher.utter_message(response)\n",
    "        return [SlotSet(\"horoscope_sign\", user_horoscope_sign)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubscribeUser(Action):\n",
    "    def name(self):\n",
    "        return \"subscribe_user\"\n",
    "    \n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        #type: (Dispatcher, DialogueStateTracker, Domain) -> List[Event]\n",
    "        \n",
    "        subscribe = tracker.get_slot('subscribe')\n",
    "        \n",
    "        if subscribe == \"True\":\n",
    "            response = \"You're successfully subscribed\"\n",
    "        if subscribe == \"False\":\n",
    "            response = \"You're successfully unsubscribed\"\n",
    "            \n",
    "        dispatcher.utter_message(response)\n",
    "        return [SlotSet(\"subscribe\", subscribe)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      ":0: UserWarning: You do not have a working installation of the service_identity module: 'No module named 'service_identity''.  Please install it from <https://pypi.python.org/pypi/service_identity> and make sure all of its dependencies are satisfied.  Without the service_identity module, Twisted can perform only rudimentary TLS client hostname verification.  Many valid certificate/hostname mappings may be rejected.\n",
      "E:\\Anaconda3\\lib\\site-packages\\pykwalify\\core.py:99: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  data = yaml.load(stream)\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Generated trackers will be deduplicated based on their unique last 5 states.\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Number of augmentation rounds is 3\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Starting data generation round 0 ... (with 1 trackers)\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 185.29it/s, # trackers=1]\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Finished phase (5 training samples found).\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Data generation rounds finished.\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Found 0 unused checkpoints\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Starting augmentation round 0 ... (with 5 trackers)\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 147.13it/s, # trackers=4]\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Finished phase (26 training samples found).\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Starting augmentation round 1 ... (with 20 trackers)\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 58.17it/s, # trackers=11]\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Finished phase (79 training samples found).\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Starting augmentation round 2 ... (with 20 trackers)\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 58.86it/s, # trackers=11]\n",
      "2020-03-21 23:03:24 DEBUG    rasa_core.training.generator  - Finished phase (128 training samples found).\n",
      "2020-03-21 23:03:25 DEBUG    rasa_core.training.generator  - Found 128 training trackers.\n",
      "2020-03-21 23:03:25 DEBUG    rasa_core.agent  - Agent trainer got kwargs: {'augmentation_factor': 50, 'epochs': 500, 'batch_size': 10, 'validation_split': 0.2}\n",
      "2020-03-21 23:03:25 INFO     rasa_core.featurizers  - Creating states and action examples from collected trackers (by MaxHistoryTrackerFeaturizer(SingleStateFeaturizer))...\n",
      "Processed trackers: 100%|██████████████████████████████████████████████| 128/128 [00:08<00:00, 15.67it/s, # actions=91]\n",
      "2020-03-21 23:03:33 INFO     rasa_core.featurizers  - Created 91 action examples.\n",
      "Processed actions: 91it [00:00, 315.06it/s, # examples=91]\n",
      "2020-03-21 23:03:33 INFO     rasa_core.policies.memoization  - Memorized 91 unique action examples.\n",
      "2020-03-21 23:03:33 INFO     rasa_core.featurizers  - Creating states and action examples from collected trackers (by MaxHistoryTrackerFeaturizer(BinarySingleStateFeaturizer))...\n",
      "Processed trackers: 100%|██████████████████████████████████████████████| 128/128 [00:07<00:00, 16.36it/s, # actions=91]\n",
      "2020-03-21 23:03:41 INFO     rasa_core.featurizers  - Created 91 action examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 22)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                7040      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 297       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 7,337\n",
      "Trainable params: 7,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:03:43 DEBUG    rasa_core.policies.keras_policy  - None\n",
      "2020-03-21 23:03:43 INFO     rasa_core.policies.keras_policy  - Fitting model with 91 total samples and a validation split of 0.2\n",
      "2020-03-21 23:03:43 DEBUG    rasa_core.policies.policy  - Parameters ignored by `model.fit(...)`: {'augmentation_factor': 50}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72 samples, validate on 19 samples\n",
      "Epoch 1/500\n",
      "72/72 [==============================] - ETA: 12s - loss: 2.2049 - acc: 0.20 - ETA: 0s - loss: 2.1508 - acc: 0.2600 - 2s 33ms/step - loss: 2.1545 - acc: 0.2222 - val_loss: 2.1275 - val_acc: 0.3158\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.1427 - acc: 0.200 - 0s 868us/step - loss: 2.0807 - acc: 0.4167 - val_loss: 2.0831 - val_acc: 0.2632\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.0848 - acc: 0.300 - 0s 1ms/step - loss: 2.0289 - acc: 0.4028 - val_loss: 2.0426 - val_acc: 0.2632\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.8723 - acc: 0.600 - 0s 868us/step - loss: 1.9617 - acc: 0.4167 - val_loss: 2.0045 - val_acc: 0.2632\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.9171 - acc: 0.300 - 0s 868us/step - loss: 1.9070 - acc: 0.4167 - val_loss: 1.9691 - val_acc: 0.2632\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.0730 - acc: 0.200 - 0s 899us/step - loss: 1.8554 - acc: 0.4167 - val_loss: 1.9320 - val_acc: 0.2632\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.8087 - acc: 0.400 - ETA: 0s - loss: 1.7792 - acc: 0.433 - 0s 933us/step - loss: 1.7774 - acc: 0.4167 - val_loss: 1.9020 - val_acc: 0.2632\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.7839 - acc: 0.400 - 0s 868us/step - loss: 1.7212 - acc: 0.4167 - val_loss: 1.8779 - val_acc: 0.2632\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.6007 - acc: 0.400 - ETA: 0s - loss: 1.7041 - acc: 0.400 - 0s 1ms/step - loss: 1.6870 - acc: 0.4167 - val_loss: 1.8579 - val_acc: 0.2632\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.6157 - acc: 0.400 - 0s 1ms/step - loss: 1.6493 - acc: 0.4167 - val_loss: 1.8359 - val_acc: 0.2632\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.8191 - acc: 0.200 - 0s 868us/step - loss: 1.5740 - acc: 0.4167 - val_loss: 1.8332 - val_acc: 0.2632\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.7153 - acc: 0.300 - 0s 868us/step - loss: 1.5600 - acc: 0.4167 - val_loss: 1.8286 - val_acc: 0.2632\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.5271 - acc: 0.500 - 0s 786us/step - loss: 1.5211 - acc: 0.4167 - val_loss: 1.8104 - val_acc: 0.2632\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3229 - acc: 0.500 - ETA: 0s - loss: 1.5262 - acc: 0.400 - 0s 1ms/step - loss: 1.5108 - acc: 0.4167 - val_loss: 1.8024 - val_acc: 0.2632\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3245 - acc: 0.500 - 0s 1ms/step - loss: 1.4864 - acc: 0.4167 - val_loss: 1.7876 - val_acc: 0.2632\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1850 - acc: 0.500 - 0s 1ms/step - loss: 1.4567 - acc: 0.4167 - val_loss: 1.7520 - val_acc: 0.2632\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2663 - acc: 0.400 - 0s 868us/step - loss: 1.3978 - acc: 0.4583 - val_loss: 1.7427 - val_acc: 0.2632\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3719 - acc: 0.500 - 0s 991us/step - loss: 1.4029 - acc: 0.4444 - val_loss: 1.7188 - val_acc: 0.2632\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2991 - acc: 0.300 - 0s 796us/step - loss: 1.3745 - acc: 0.4583 - val_loss: 1.6906 - val_acc: 0.3158\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.4933 - acc: 0.500 - ETA: 0s - loss: 1.3296 - acc: 0.528 - 0s 1ms/step - loss: 1.3367 - acc: 0.5139 - val_loss: 1.6725 - val_acc: 0.3684\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2668 - acc: 0.500 - 0s 943us/step - loss: 1.2969 - acc: 0.5694 - val_loss: 1.6659 - val_acc: 0.3158\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9686 - acc: 0.600 - 0s 1ms/step - loss: 1.3070 - acc: 0.5139 - val_loss: 1.6486 - val_acc: 0.3158\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3592 - acc: 0.400 - 0s 868us/step - loss: 1.2557 - acc: 0.5278 - val_loss: 1.6184 - val_acc: 0.3684\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2686 - acc: 0.400 - 0s 898us/step - loss: 1.2534 - acc: 0.5417 - val_loss: 1.6087 - val_acc: 0.3684\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1398 - acc: 0.700 - 0s 1ms/step - loss: 1.2221 - acc: 0.5972 - val_loss: 1.5791 - val_acc: 0.3684\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1203 - acc: 0.700 - 0s 1ms/step - loss: 1.1958 - acc: 0.5972 - val_loss: 1.5450 - val_acc: 0.3684\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0996 - acc: 0.700 - 0s 1ms/step - loss: 1.1511 - acc: 0.5972 - val_loss: 1.5208 - val_acc: 0.3684\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0588 - acc: 0.700 - 0s 896us/step - loss: 1.1231 - acc: 0.6250 - val_loss: 1.4883 - val_acc: 0.3684\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1903 - acc: 0.700 - ETA: 0s - loss: 1.0978 - acc: 0.614 - 0s 1ms/step - loss: 1.0949 - acc: 0.6111 - val_loss: 1.4683 - val_acc: 0.3684\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9140 - acc: 0.700 - 0s 883us/step - loss: 1.0819 - acc: 0.6389 - val_loss: 1.4433 - val_acc: 0.3684\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2673 - acc: 0.600 - 0s 887us/step - loss: 1.0484 - acc: 0.6111 - val_loss: 1.4403 - val_acc: 0.3684\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8894 - acc: 0.700 - 0s 868us/step - loss: 1.0504 - acc: 0.6389 - val_loss: 1.4084 - val_acc: 0.3684\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.7710 - acc: 0.900 - 0s 868us/step - loss: 1.0275 - acc: 0.6111 - val_loss: 1.3768 - val_acc: 0.4211\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9527 - acc: 0.600 - 0s 1ms/step - loss: 0.9752 - acc: 0.6667 - val_loss: 1.3671 - val_acc: 0.3684\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.7961 - acc: 0.700 - 0s 1ms/step - loss: 0.9586 - acc: 0.5972 - val_loss: 1.3397 - val_acc: 0.4737\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9877 - acc: 0.700 - 0s 868us/step - loss: 0.9377 - acc: 0.7222 - val_loss: 1.3210 - val_acc: 0.4211\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2031 - acc: 0.600 - ETA: 0s - loss: 0.9053 - acc: 0.700 - 0s 1ms/step - loss: 0.8921 - acc: 0.7083 - val_loss: 1.2942 - val_acc: 0.3684\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0441 - acc: 0.700 - 0s 1ms/step - loss: 0.8925 - acc: 0.6944 - val_loss: 1.2680 - val_acc: 0.3684\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9288 - acc: 0.700 - 0s 824us/step - loss: 0.8895 - acc: 0.7222 - val_loss: 1.2454 - val_acc: 0.3684\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9662 - acc: 0.700 - ETA: 0s - loss: 0.8216 - acc: 0.757 - 0s 1ms/step - loss: 0.8224 - acc: 0.7639 - val_loss: 1.2198 - val_acc: 0.3684\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5600 - acc: 0.900 - 0s 868us/step - loss: 0.8174 - acc: 0.7083 - val_loss: 1.1838 - val_acc: 0.5263\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8019 - acc: 0.700 - ETA: 0s - loss: 0.8194 - acc: 0.728 - 0s 1ms/step - loss: 0.8066 - acc: 0.7361 - val_loss: 1.1486 - val_acc: 0.5263\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.6191 - acc: 0.800 - ETA: 0s - loss: 0.7218 - acc: 0.842 - 0s 1ms/step - loss: 0.7179 - acc: 0.8472 - val_loss: 1.1139 - val_acc: 0.5263\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.7153 - acc: 0.800 - ETA: 0s - loss: 0.7493 - acc: 0.814 - 0s 1ms/step - loss: 0.7418 - acc: 0.8194 - val_loss: 1.0973 - val_acc: 0.5263\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5921 - acc: 0.800 - ETA: 0s - loss: 0.7207 - acc: 0.785 - 0s 1ms/step - loss: 0.7273 - acc: 0.7778 - val_loss: 1.0431 - val_acc: 0.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.6408 - acc: 1.000 - 0s 851us/step - loss: 0.7382 - acc: 0.8750 - val_loss: 1.0204 - val_acc: 0.7895\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4891 - acc: 0.900 - 0s 1ms/step - loss: 0.6600 - acc: 0.8750 - val_loss: 0.9886 - val_acc: 0.6842\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.6049 - acc: 1.000 - ETA: 0s - loss: 0.6363 - acc: 0.885 - 0s 1ms/step - loss: 0.6354 - acc: 0.8889 - val_loss: 0.9605 - val_acc: 0.6842\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5161 - acc: 0.800 - ETA: 0s - loss: 0.6526 - acc: 0.857 - 0s 1ms/step - loss: 0.6480 - acc: 0.8611 - val_loss: 0.9323 - val_acc: 0.7368\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8655 - acc: 0.900 - 0s 830us/step - loss: 0.6037 - acc: 0.8889 - val_loss: 0.9028 - val_acc: 0.7895\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8649 - acc: 0.900 - 0s 868us/step - loss: 0.6157 - acc: 0.8889 - val_loss: 0.8874 - val_acc: 0.7895\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.6493 - acc: 0.900 - ETA: 0s - loss: 0.5667 - acc: 0.900 - 0s 1ms/step - loss: 0.5718 - acc: 0.9028 - val_loss: 0.8664 - val_acc: 0.8421\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8471 - acc: 0.700 - 0s 1ms/step - loss: 0.5865 - acc: 0.8611 - val_loss: 0.8413 - val_acc: 0.8421\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3249 - acc: 1.000 - 0s 1ms/step - loss: 0.4907 - acc: 0.9583 - val_loss: 0.8108 - val_acc: 0.8421\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.7224 - acc: 0.700 - 0s 918us/step - loss: 0.5556 - acc: 0.8472 - val_loss: 0.7926 - val_acc: 0.8421\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5106 - acc: 0.900 - 0s 868us/step - loss: 0.5252 - acc: 0.9028 - val_loss: 0.7755 - val_acc: 0.8421\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5131 - acc: 0.800 - 0s 1ms/step - loss: 0.5100 - acc: 0.9167 - val_loss: 0.7639 - val_acc: 0.8421\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8792 - acc: 0.700 - 0s 1ms/step - loss: 0.4709 - acc: 0.8750 - val_loss: 0.7179 - val_acc: 0.8421\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4416 - acc: 0.900 - 0s 996us/step - loss: 0.4324 - acc: 0.9583 - val_loss: 0.6989 - val_acc: 0.8421\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8137 - acc: 0.900 - ETA: 0s - loss: 0.4215 - acc: 0.914 - 0s 1ms/step - loss: 0.4529 - acc: 0.8889 - val_loss: 0.6560 - val_acc: 0.8421\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5788 - acc: 0.900 - ETA: 0s - loss: 0.3852 - acc: 0.957 - 0s 1ms/step - loss: 0.3797 - acc: 0.9583 - val_loss: 0.6444 - val_acc: 0.8421\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4681 - acc: 0.900 - ETA: 0s - loss: 0.4321 - acc: 0.942 - 0s 1ms/step - loss: 0.4237 - acc: 0.9444 - val_loss: 0.6411 - val_acc: 0.8421\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4595 - acc: 0.900 - ETA: 0s - loss: 0.3717 - acc: 0.942 - 0s 1ms/step - loss: 0.3703 - acc: 0.9444 - val_loss: 0.6416 - val_acc: 0.8421\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1935 - acc: 1.000 - ETA: 0s - loss: 0.3868 - acc: 0.942 - 0s 1ms/step - loss: 0.3786 - acc: 0.9444 - val_loss: 0.6263 - val_acc: 0.8421\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3283 - acc: 0.900 - 0s 1ms/step - loss: 0.3626 - acc: 0.9444 - val_loss: 0.6069 - val_acc: 0.8421\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3688 - acc: 0.900 - 0s 1ms/step - loss: 0.3370 - acc: 0.9444 - val_loss: 0.5948 - val_acc: 0.8421\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3160 - acc: 0.900 - 0s 1ms/step - loss: 0.3199 - acc: 0.9444 - val_loss: 0.6119 - val_acc: 0.8421\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2611 - acc: 0.900 - 0s 1ms/step - loss: 0.3528 - acc: 0.9167 - val_loss: 0.5858 - val_acc: 0.8421\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2327 - acc: 1.000 - 0s 1ms/step - loss: 0.3439 - acc: 0.9444 - val_loss: 0.5736 - val_acc: 0.8421\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3997 - acc: 1.000 - 0s 1ms/step - loss: 0.3117 - acc: 0.9444 - val_loss: 0.5301 - val_acc: 0.8421\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1100 - acc: 1.000 - ETA: 0s - loss: 0.3232 - acc: 0.957 - 0s 1ms/step - loss: 0.3162 - acc: 0.9583 - val_loss: 0.5202 - val_acc: 0.8421\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2849 - acc: 1.000 - ETA: 0s - loss: 0.2772 - acc: 0.971 - 0s 1ms/step - loss: 0.2961 - acc: 0.9583 - val_loss: 0.4983 - val_acc: 0.8421\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3486 - acc: 1.000 - 0s 868us/step - loss: 0.2765 - acc: 0.9583 - val_loss: 0.4923 - val_acc: 0.8421\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2152 - acc: 1.000 - 0s 1ms/step - loss: 0.2735 - acc: 0.9583 - val_loss: 0.4887 - val_acc: 0.8421\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2537 - acc: 1.000 - 0s 1ms/step - loss: 0.2886 - acc: 0.9306 - val_loss: 0.4996 - val_acc: 0.8421\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3079 - acc: 0.900 - ETA: 0s - loss: 0.2556 - acc: 0.957 - 0s 1ms/step - loss: 0.2498 - acc: 0.9583 - val_loss: 0.4888 - val_acc: 0.8421\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3301 - acc: 0.900 - 0s 929us/step - loss: 0.2640 - acc: 0.9583 - val_loss: 0.4799 - val_acc: 0.8421\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2981 - acc: 0.900 - ETA: 0s - loss: 0.2242 - acc: 0.957 - 0s 1ms/step - loss: 0.2257 - acc: 0.9583 - val_loss: 0.4811 - val_acc: 0.8421\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2725 - acc: 0.900 - ETA: 0s - loss: 0.2563 - acc: 0.957 - 0s 1ms/step - loss: 0.2514 - acc: 0.9583 - val_loss: 0.4734 - val_acc: 0.8421\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3301 - acc: 0.900 - ETA: 0s - loss: 0.2529 - acc: 0.957 - 0s 1ms/step - loss: 0.2531 - acc: 0.9583 - val_loss: 0.4590 - val_acc: 0.8421\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1148 - acc: 1.000 - 0s 1ms/step - loss: 0.2064 - acc: 0.9583 - val_loss: 0.4408 - val_acc: 0.8421\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1111 - acc: 1.000 - 0s 868us/step - loss: 0.2215 - acc: 0.9583 - val_loss: 0.4509 - val_acc: 0.8421\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3950 - acc: 0.900 - ETA: 0s - loss: 0.2294 - acc: 0.928 - 0s 1ms/step - loss: 0.2263 - acc: 0.9306 - val_loss: 0.4432 - val_acc: 0.8421\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0684 - acc: 1.000 - 0s 861us/step - loss: 0.1889 - acc: 0.9861 - val_loss: 0.4460 - val_acc: 0.8421\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2145 - acc: 1.000 - ETA: 0s - loss: 0.2245 - acc: 0.957 - 0s 1ms/step - loss: 0.2256 - acc: 0.9583 - val_loss: 0.4312 - val_acc: 0.8421\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1111 - acc: 1.000 - 0s 860us/step - loss: 0.1601 - acc: 0.9583 - val_loss: 0.4024 - val_acc: 0.8421\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1550 - acc: 1.000 - 0s 1ms/step - loss: 0.1701 - acc: 0.9722 - val_loss: 0.3919 - val_acc: 0.8421\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0961 - acc: 1.000 - ETA: 0s - loss: 0.1356 - acc: 0.983 - 0s 1ms/step - loss: 0.1824 - acc: 0.9583 - val_loss: 0.3886 - val_acc: 0.8421\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1762 - acc: 1.000 - 0s 769us/step - loss: 0.1829 - acc: 0.9444 - val_loss: 0.3813 - val_acc: 0.8421\n",
      "Epoch 90/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 0.1196 - acc: 1.000 - ETA: 0s - loss: 0.1659 - acc: 0.966 - 0s 2ms/step - loss: 0.1839 - acc: 0.9722 - val_loss: 0.3824 - val_acc: 0.8421\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1423 - acc: 0.900 - 0s 1ms/step - loss: 0.1687 - acc: 0.9583 - val_loss: 0.3607 - val_acc: 0.8421\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1833 - acc: 0.900 - 0s 868us/step - loss: 0.1659 - acc: 0.9444 - val_loss: 0.3308 - val_acc: 0.8421\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0794 - acc: 1.000 - 0s 868us/step - loss: 0.1484 - acc: 0.9861 - val_loss: 0.3458 - val_acc: 0.8421\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1753 - acc: 1.000 - ETA: 0s - loss: 0.1683 - acc: 0.950 - 0s 1ms/step - loss: 0.1698 - acc: 0.9444 - val_loss: 0.3161 - val_acc: 0.8421\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1927 - acc: 0.900 - ETA: 0s - loss: 0.1346 - acc: 0.983 - 0s 1ms/step - loss: 0.1284 - acc: 0.9861 - val_loss: 0.3204 - val_acc: 0.8421\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1492 - acc: 1.000 - ETA: 0s - loss: 0.1497 - acc: 0.983 - 0s 1ms/step - loss: 0.1372 - acc: 0.9861 - val_loss: 0.3331 - val_acc: 0.8421\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2369 - acc: 1.000 - ETA: 0s - loss: 0.1443 - acc: 0.971 - 0s 1ms/step - loss: 0.1414 - acc: 0.9722 - val_loss: 0.3582 - val_acc: 0.8421\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1437 - acc: 1.000 - ETA: 0s - loss: 0.1478 - acc: 0.983 - 0s 1ms/step - loss: 0.1331 - acc: 0.9861 - val_loss: 0.3519 - val_acc: 0.8421\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1173 - acc: 0.900 - 0s 951us/step - loss: 0.1270 - acc: 0.9722 - val_loss: 0.3362 - val_acc: 0.8421\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0500 - acc: 1.000 - 0s 887us/step - loss: 0.1217 - acc: 0.9722 - val_loss: 0.3337 - val_acc: 0.8421\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1028 - acc: 1.000 - 0s 891us/step - loss: 0.1549 - acc: 0.9722 - val_loss: 0.3492 - val_acc: 0.8421\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0328 - acc: 1.000 - ETA: 0s - loss: 0.1177 - acc: 0.966 - 0s 1ms/step - loss: 0.1354 - acc: 0.9722 - val_loss: 0.3172 - val_acc: 0.8421\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0586 - acc: 1.000 - 0s 868us/step - loss: 0.1054 - acc: 0.9861 - val_loss: 0.2966 - val_acc: 0.8421\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0240 - acc: 1.000 - 0s 1ms/step - loss: 0.1049 - acc: 1.0000 - val_loss: 0.2885 - val_acc: 0.8421\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1182 - acc: 1.000 - 0s 843us/step - loss: 0.1447 - acc: 0.9722 - val_loss: 0.3367 - val_acc: 0.8421\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4607 - acc: 0.800 - 0s 1ms/step - loss: 0.1357 - acc: 0.9722 - val_loss: 0.3400 - val_acc: 0.7895\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0724 - acc: 1.000 - 0s 868us/step - loss: 0.1234 - acc: 0.9861 - val_loss: 0.3233 - val_acc: 0.7895\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0239 - acc: 1.000 - ETA: 0s - loss: 0.1222 - acc: 0.957 - 0s 1ms/step - loss: 0.1352 - acc: 0.9444 - val_loss: 0.2841 - val_acc: 0.7895\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3457 - acc: 0.800 - 0s 868us/step - loss: 0.1063 - acc: 0.9722 - val_loss: 0.2784 - val_acc: 0.8421\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1756 - acc: 1.000 - 0s 868us/step - loss: 0.1160 - acc: 0.9722 - val_loss: 0.2960 - val_acc: 0.8421\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0634 - acc: 1.000 - 0s 1ms/step - loss: 0.0928 - acc: 0.9861 - val_loss: 0.2941 - val_acc: 0.8421\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1000 - acc: 1.000 - 0s 1ms/step - loss: 0.0885 - acc: 0.9861 - val_loss: 0.2956 - val_acc: 0.8421\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1694 - acc: 0.900 - ETA: 0s - loss: 0.1210 - acc: 0.971 - 0s 1ms/step - loss: 0.1186 - acc: 0.9722 - val_loss: 0.3437 - val_acc: 0.7895\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0254 - acc: 1.000 - 0s 1ms/step - loss: 0.1047 - acc: 0.9722 - val_loss: 0.3089 - val_acc: 0.7895\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0609 - acc: 1.000 - 0s 975us/step - loss: 0.1043 - acc: 0.9583 - val_loss: 0.3118 - val_acc: 0.7895\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0384 - acc: 1.000 - 0s 1ms/step - loss: 0.0866 - acc: 0.9861 - val_loss: 0.2765 - val_acc: 0.8421\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0150 - acc: 1.000 - 0s 837us/step - loss: 0.1243 - acc: 0.9722 - val_loss: 0.3075 - val_acc: 0.7895\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1573 - acc: 1.000 - 0s 1ms/step - loss: 0.0805 - acc: 0.9861 - val_loss: 0.2834 - val_acc: 0.7895\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0187 - acc: 1.000 - 0s 868us/step - loss: 0.0934 - acc: 0.9861 - val_loss: 0.2962 - val_acc: 0.7895\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0921 - acc: 1.000 - 0s 815us/step - loss: 0.1041 - acc: 0.9861 - val_loss: 0.3140 - val_acc: 0.7895\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0553 - acc: 1.000 - 0s 796us/step - loss: 0.0896 - acc: 0.9861 - val_loss: 0.3290 - val_acc: 0.7895\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0697 - acc: 1.000 - 0s 868us/step - loss: 0.0805 - acc: 0.9861 - val_loss: 0.3118 - val_acc: 0.7895\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0815 - acc: 1.000 - 0s 1ms/step - loss: 0.0794 - acc: 1.0000 - val_loss: 0.2678 - val_acc: 0.7895\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0210 - acc: 1.000 - 0s 1ms/step - loss: 0.0809 - acc: 1.0000 - val_loss: 0.2931 - val_acc: 0.7895\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0541 - acc: 1.000 - 0s 1ms/step - loss: 0.0927 - acc: 0.9861 - val_loss: 0.2746 - val_acc: 0.7895\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0880 - acc: 1.000 - 0s 929us/step - loss: 0.0818 - acc: 1.0000 - val_loss: 0.2479 - val_acc: 0.7895\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0160 - acc: 1.000 - 0s 868us/step - loss: 0.0820 - acc: 0.9861 - val_loss: 0.2758 - val_acc: 0.7895\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0562 - acc: 1.000 - 0s 942us/step - loss: 0.0957 - acc: 0.9722 - val_loss: 0.2911 - val_acc: 0.7895\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3284 - acc: 0.900 - 0s 868us/step - loss: 0.1036 - acc: 0.9722 - val_loss: 0.2538 - val_acc: 0.7895\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0201 - acc: 1.000 - 0s 868us/step - loss: 0.0658 - acc: 0.9861 - val_loss: 0.2503 - val_acc: 0.7895\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0371 - acc: 1.000 - 0s 868us/step - loss: 0.0768 - acc: 0.9861 - val_loss: 0.2110 - val_acc: 0.8421\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0198 - acc: 1.000 - 0s 1ms/step - loss: 0.1123 - acc: 0.9583 - val_loss: 0.2372 - val_acc: 0.7895\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0427 - acc: 1.000 - 0s 868us/step - loss: 0.0819 - acc: 1.0000 - val_loss: 0.2440 - val_acc: 0.7895\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0967 - acc: 1.000 - 0s 868us/step - loss: 0.0648 - acc: 1.0000 - val_loss: 0.2607 - val_acc: 0.7895\n",
      "Epoch 135/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 0.0698 - acc: 1.000 - ETA: 0s - loss: 0.0863 - acc: 0.985 - 0s 1ms/step - loss: 0.0840 - acc: 0.9861 - val_loss: 0.2552 - val_acc: 0.7895\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0216 - acc: 1.000 - 0s 969us/step - loss: 0.1046 - acc: 0.9583 - val_loss: 0.3004 - val_acc: 0.7895\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0086 - acc: 1.000 - ETA: 0s - loss: 0.0846 - acc: 0.985 - 0s 1ms/step - loss: 0.0823 - acc: 0.9861 - val_loss: 0.2816 - val_acc: 0.7895\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0391 - acc: 1.000 - ETA: 0s - loss: 0.0407 - acc: 0.983 - 0s 1ms/step - loss: 0.0655 - acc: 0.9861 - val_loss: 0.2571 - val_acc: 0.7895\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0407 - acc: 1.000 - 0s 820us/step - loss: 0.0606 - acc: 1.0000 - val_loss: 0.2460 - val_acc: 0.7895\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0628 - acc: 1.000 - 0s 1ms/step - loss: 0.0723 - acc: 1.0000 - val_loss: 0.2703 - val_acc: 0.7895\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0656 - acc: 1.000 - 0s 834us/step - loss: 0.0703 - acc: 0.9861 - val_loss: 0.2412 - val_acc: 0.7895\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0241 - acc: 1.000 - ETA: 0s - loss: 0.0565 - acc: 0.985 - 0s 1ms/step - loss: 0.0553 - acc: 0.9861 - val_loss: 0.2192 - val_acc: 0.7895\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0134 - acc: 1.000 - ETA: 0s - loss: 0.0619 - acc: 1.000 - 0s 1ms/step - loss: 0.0615 - acc: 1.0000 - val_loss: 0.2590 - val_acc: 0.7895\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0139 - acc: 1.000 - ETA: 0s - loss: 0.0475 - acc: 0.983 - 0s 1ms/step - loss: 0.0633 - acc: 0.9861 - val_loss: 0.2137 - val_acc: 0.8421\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1502 - acc: 1.000 - 0s 782us/step - loss: 0.0683 - acc: 0.9861 - val_loss: 0.2384 - val_acc: 0.7895\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1792 - acc: 1.000 - ETA: 0s - loss: 0.0799 - acc: 0.985 - 0s 1ms/step - loss: 0.0794 - acc: 0.9861 - val_loss: 0.2548 - val_acc: 0.7895\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0885 - acc: 1.000 - 0s 806us/step - loss: 0.0576 - acc: 0.9861 - val_loss: 0.2532 - val_acc: 0.7895\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1752 - acc: 0.900 - ETA: 0s - loss: 0.0751 - acc: 0.985 - 0s 1ms/step - loss: 0.0730 - acc: 0.9861 - val_loss: 0.2735 - val_acc: 0.7895\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1387 - acc: 1.000 - 0s 969us/step - loss: 0.0605 - acc: 0.9861 - val_loss: 0.2514 - val_acc: 0.7895\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0403 - acc: 1.000 - ETA: 0s - loss: 0.0436 - acc: 1.000 - 0s 1ms/step - loss: 0.0477 - acc: 1.0000 - val_loss: 0.2866 - val_acc: 0.7895\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0329 - acc: 1.000 - ETA: 0s - loss: 0.0480 - acc: 1.000 - 0s 1ms/step - loss: 0.0471 - acc: 1.0000 - val_loss: 0.2593 - val_acc: 0.7895\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1252 - acc: 1.000 - 0s 868us/step - loss: 0.0608 - acc: 1.0000 - val_loss: 0.2312 - val_acc: 0.7895\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0829 - acc: 1.000 - 0s 1ms/step - loss: 0.0605 - acc: 1.0000 - val_loss: 0.2385 - val_acc: 0.7895\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1142 - acc: 1.000 - 0s 868us/step - loss: 0.0463 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.8421\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2194 - acc: 0.900 - 0s 868us/step - loss: 0.0657 - acc: 0.9861 - val_loss: 0.2352 - val_acc: 0.7895\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0140 - acc: 1.000 - ETA: 0s - loss: 0.0578 - acc: 0.971 - 0s 1ms/step - loss: 0.0690 - acc: 0.9722 - val_loss: 0.2490 - val_acc: 0.7895\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0364 - acc: 1.000 - ETA: 0s - loss: 0.0446 - acc: 1.000 - 0s 1ms/step - loss: 0.0543 - acc: 0.9861 - val_loss: 0.1985 - val_acc: 0.8421\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0271 - acc: 1.000 - 0s 1ms/step - loss: 0.0666 - acc: 0.9722 - val_loss: 0.2774 - val_acc: 0.7895\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0365 - acc: 1.000 - 0s 899us/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.2645 - val_acc: 0.7895\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0087 - acc: 1.000 - ETA: 0s - loss: 0.0639 - acc: 0.971 - 0s 1ms/step - loss: 0.0678 - acc: 0.9722 - val_loss: 0.2368 - val_acc: 0.7895\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0870 - acc: 1.000 - ETA: 0s - loss: 0.0807 - acc: 0.971 - 0s 1ms/step - loss: 0.0856 - acc: 0.9722 - val_loss: 0.2355 - val_acc: 0.7895\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0989 - acc: 0.900 - ETA: 0s - loss: 0.0536 - acc: 0.985 - 0s 1ms/step - loss: 0.0523 - acc: 0.9861 - val_loss: 0.2122 - val_acc: 0.7895\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0227 - acc: 1.000 - 0s 1ms/step - loss: 0.0653 - acc: 0.9861 - val_loss: 0.2242 - val_acc: 0.7895\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1204 - acc: 1.000 - 0s 1ms/step - loss: 0.0500 - acc: 0.9861 - val_loss: 0.2212 - val_acc: 0.7895\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0988 - acc: 1.000 - 0s 1ms/step - loss: 0.0461 - acc: 1.0000 - val_loss: 0.2172 - val_acc: 0.7895\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1012 - acc: 1.000 - ETA: 0s - loss: 0.0485 - acc: 1.000 - 0s 1ms/step - loss: 0.0357 - acc: 1.0000 - val_loss: 0.2568 - val_acc: 0.7895\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0182 - acc: 1.000 - 0s 1ms/step - loss: 0.0436 - acc: 1.0000 - val_loss: 0.1999 - val_acc: 0.8421\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1981 - acc: 0.900 - 0s 927us/step - loss: 0.0615 - acc: 0.9861 - val_loss: 0.2879 - val_acc: 0.7895\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0714 - acc: 0.985 - 0s 1ms/step - loss: 0.0737 - acc: 0.9861 - val_loss: 0.3012 - val_acc: 0.7895\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0091 - acc: 1.000 - 0s 868us/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.2965 - val_acc: 0.7895\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0080 - acc: 1.000 - 0s 868us/step - loss: 0.0563 - acc: 0.9861 - val_loss: 0.2793 - val_acc: 0.7895\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0356 - acc: 1.000 - ETA: 0s - loss: 0.0604 - acc: 0.985 - 0s 1ms/step - loss: 0.0588 - acc: 0.9861 - val_loss: 0.2448 - val_acc: 0.7895\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0302 - acc: 1.000 - ETA: 0s - loss: 0.0464 - acc: 0.985 - 0s 1ms/step - loss: 0.0572 - acc: 0.9722 - val_loss: 0.2046 - val_acc: 0.8421\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0308 - acc: 1.000 - 0s 2ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.2280 - val_acc: 0.7895\n",
      "Epoch 175/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1067 - acc: 1.000 - ETA: 0s - loss: 0.0470 - acc: 0.985 - 0s 2ms/step - loss: 0.0457 - acc: 0.9861 - val_loss: 0.2712 - val_acc: 0.7895\n",
      "Epoch 176/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0257 - acc: 1.000 - ETA: 0s - loss: 0.0378 - acc: 0.983 - 0s 1ms/step - loss: 0.0425 - acc: 0.9861 - val_loss: 0.2895 - val_acc: 0.7895\n",
      "Epoch 177/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0434 - acc: 1.000 - ETA: 0s - loss: 0.0307 - acc: 1.000 - 0s 1ms/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.2568 - val_acc: 0.7895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0120 - acc: 1.000 - 0s 980us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.2177 - val_acc: 0.8421\n",
      "Epoch 179/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0161 - acc: 1.000 - 0s 1ms/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.2468 - val_acc: 0.7895\n",
      "Epoch 180/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0127 - acc: 1.000 - ETA: 0s - loss: 0.0606 - acc: 0.980 - 0s 1ms/step - loss: 0.0553 - acc: 0.9722 - val_loss: 0.2741 - val_acc: 0.7895\n",
      "Epoch 181/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0355 - acc: 1.000 - 0s 1ms/step - loss: 0.0357 - acc: 1.0000 - val_loss: 0.2432 - val_acc: 0.7895\n",
      "Epoch 182/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0263 - acc: 1.000 - ETA: 0s - loss: 0.0509 - acc: 1.000 - 0s 1ms/step - loss: 0.0444 - acc: 1.0000 - val_loss: 0.2303 - val_acc: 0.7895\n",
      "Epoch 183/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0724 - acc: 1.000 - ETA: 0s - loss: 0.0445 - acc: 1.000 - 0s 2ms/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.2378 - val_acc: 0.7895\n",
      "Epoch 184/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0243 - acc: 1.000 - ETA: 0s - loss: 0.0369 - acc: 0.985 - 0s 1ms/step - loss: 0.0360 - acc: 0.9861 - val_loss: 0.3058 - val_acc: 0.7895\n",
      "Epoch 185/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0076 - acc: 1.000 - ETA: 0s - loss: 0.0732 - acc: 0.971 - 0s 1ms/step - loss: 0.0714 - acc: 0.9722 - val_loss: 0.3224 - val_acc: 0.7895\n",
      "Epoch 186/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0177 - acc: 1.000 - 0s 1ms/step - loss: 0.0390 - acc: 0.9861 - val_loss: 0.3031 - val_acc: 0.7895\n",
      "Epoch 187/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0389 - acc: 1.000 - ETA: 0s - loss: 0.0423 - acc: 1.000 - 0s 1ms/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.2745 - val_acc: 0.7895\n",
      "Epoch 188/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0914 - acc: 1.000 - ETA: 0s - loss: 0.0546 - acc: 0.983 - 0s 1ms/step - loss: 0.0477 - acc: 0.9861 - val_loss: 0.3515 - val_acc: 0.7895\n",
      "Epoch 189/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0714 - acc: 1.000 - 0s 1ms/step - loss: 0.0619 - acc: 0.9722 - val_loss: 0.3367 - val_acc: 0.7895\n",
      "Epoch 190/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0580 - acc: 0.985 - 0s 1ms/step - loss: 0.0570 - acc: 0.9861 - val_loss: 0.3231 - val_acc: 0.7895\n",
      "Epoch 191/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0049 - acc: 1.000 - ETA: 0s - loss: 0.0414 - acc: 0.983 - 0s 1ms/step - loss: 0.0365 - acc: 0.9861 - val_loss: 0.2422 - val_acc: 0.7895\n",
      "Epoch 192/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.000 - 0s 920us/step - loss: 0.0290 - acc: 1.0000 - val_loss: 0.2712 - val_acc: 0.7895\n",
      "Epoch 193/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0099 - acc: 1.000 - ETA: 0s - loss: 0.0635 - acc: 0.985 - 0s 1ms/step - loss: 0.0618 - acc: 0.9861 - val_loss: 0.3547 - val_acc: 0.7895\n",
      "Epoch 194/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2733 - acc: 0.900 - ETA: 0s - loss: 0.0639 - acc: 0.983 - 0s 2ms/step - loss: 0.0552 - acc: 0.9861 - val_loss: 0.3755 - val_acc: 0.7895\n",
      "Epoch 195/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1081 - acc: 1.000 - ETA: 0s - loss: 0.0425 - acc: 0.985 - 0s 1ms/step - loss: 0.0432 - acc: 0.9861 - val_loss: 0.2852 - val_acc: 0.7895\n",
      "Epoch 196/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0783 - acc: 1.000 - ETA: 0s - loss: 0.0260 - acc: 1.000 - 0s 1ms/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.2493 - val_acc: 0.7895\n",
      "Epoch 197/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2385 - acc: 0.900 - 0s 1ms/step - loss: 0.0768 - acc: 0.9722 - val_loss: 0.3598 - val_acc: 0.7895\n",
      "Epoch 198/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0767 - acc: 1.000 - 0s 1ms/step - loss: 0.0533 - acc: 0.9722 - val_loss: 0.3134 - val_acc: 0.7895\n",
      "Epoch 199/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0327 - acc: 1.000 - 0s 1ms/step - loss: 0.0318 - acc: 1.0000 - val_loss: 0.2825 - val_acc: 0.7895\n",
      "Epoch 200/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0392 - acc: 1.000 - ETA: 0s - loss: 0.0378 - acc: 0.985 - 0s 1ms/step - loss: 0.0368 - acc: 0.9861 - val_loss: 0.2468 - val_acc: 0.7895\n",
      "Epoch 201/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0075 - acc: 1.000 - ETA: 0s - loss: 0.0209 - acc: 1.000 - 0s 1ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.1978 - val_acc: 0.8421\n",
      "Epoch 202/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0690 - acc: 1.000 - ETA: 0s - loss: 0.0215 - acc: 1.000 - 0s 1ms/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.2292 - val_acc: 0.7895\n",
      "Epoch 203/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0669 - acc: 1.000 - 0s 1ms/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.1765 - val_acc: 0.8947\n",
      "Epoch 204/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.000 - 0s 1ms/step - loss: 0.0342 - acc: 1.0000 - val_loss: 0.2012 - val_acc: 0.8421\n",
      "Epoch 205/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0186 - acc: 1.000 - ETA: 0s - loss: 0.0526 - acc: 0.983 - 0s 1ms/step - loss: 0.0444 - acc: 0.9861 - val_loss: 0.2491 - val_acc: 0.7895\n",
      "Epoch 206/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0185 - acc: 1.000 - 0s 1ms/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.2646 - val_acc: 0.7895\n",
      "Epoch 207/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0070 - acc: 1.000 - ETA: 0s - loss: 0.0318 - acc: 0.983 - 0s 2ms/step - loss: 0.0271 - acc: 0.9861 - val_loss: 0.3044 - val_acc: 0.7895\n",
      "Epoch 208/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1321 - acc: 0.900 - ETA: 0s - loss: 0.0442 - acc: 0.983 - 0s 2ms/step - loss: 0.0387 - acc: 0.9861 - val_loss: 0.3346 - val_acc: 0.7895\n",
      "Epoch 209/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0401 - acc: 1.000 - ETA: 0s - loss: 0.0343 - acc: 1.000 - 0s 1ms/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.3927 - val_acc: 0.7895\n",
      "Epoch 210/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0205 - acc: 1.000 - ETA: 0s - loss: 0.0315 - acc: 0.985 - 0s 1ms/step - loss: 0.0315 - acc: 0.9861 - val_loss: 0.2715 - val_acc: 0.7895\n",
      "Epoch 211/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0225 - acc: 1.000 - ETA: 0s - loss: 0.0268 - acc: 0.985 - 0s 2ms/step - loss: 0.0262 - acc: 0.9861 - val_loss: 0.2301 - val_acc: 0.7895\n",
      "Epoch 212/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0309 - acc: 1.000 - ETA: 0s - loss: 0.0361 - acc: 0.975 - 0s 1ms/step - loss: 0.0377 - acc: 0.9861 - val_loss: 0.2357 - val_acc: 0.7895\n",
      "Epoch 213/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0169 - acc: 1.000 - ETA: 0s - loss: 0.0261 - acc: 1.000 - 0s 2ms/step - loss: 0.0369 - acc: 0.9861 - val_loss: 0.3134 - val_acc: 0.7895\n",
      "Epoch 214/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0510 - acc: 1.000 - ETA: 0s - loss: 0.0228 - acc: 1.000 - 0s 1ms/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.3924 - val_acc: 0.7895\n",
      "Epoch 215/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0575 - acc: 0.966 - 0s 1ms/step - loss: 0.0482 - acc: 0.9722 - val_loss: 0.2897 - val_acc: 0.7895\n",
      "Epoch 216/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0139 - acc: 1.000 - ETA: 0s - loss: 0.0365 - acc: 0.985 - 0s 2ms/step - loss: 0.0355 - acc: 0.9861 - val_loss: 0.3638 - val_acc: 0.7895\n",
      "Epoch 217/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0489 - acc: 0.983 - 0s 1ms/step - loss: 0.0411 - acc: 0.9861 - val_loss: 0.4207 - val_acc: 0.7895\n",
      "Epoch 218/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1034 - acc: 1.000 - ETA: 0s - loss: 0.0290 - acc: 1.000 - 0s 1ms/step - loss: 0.0290 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 0.7895\n",
      "Epoch 219/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.000 - 0s 1ms/step - loss: 0.0420 - acc: 0.9861 - val_loss: 0.3955 - val_acc: 0.7895\n",
      "Epoch 220/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0243 - acc: 1.000 - 0s 1ms/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.3144 - val_acc: 0.7895\n",
      "Epoch 221/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.8650e-04 - acc: 1.000 - ETA: 0s - loss: 0.0165 - acc: 1.0000    - 0s 1ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.2434 - val_acc: 0.7895\n",
      "Epoch 222/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0103 - acc: 1.000 - ETA: 0s - loss: 0.0196 - acc: 1.000 - 0s 2ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.2360 - val_acc: 0.7895\n",
      "Epoch 223/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0174 - acc: 1.000 - 0s 2ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.2407 - val_acc: 0.7895\n",
      "Epoch 224/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0140 - acc: 1.000 - ETA: 0s - loss: 0.0465 - acc: 0.985 - 0s 1ms/step - loss: 0.0553 - acc: 0.9861 - val_loss: 0.2340 - val_acc: 0.7895\n",
      "Epoch 225/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0281 - acc: 0.985 - 0s 1ms/step - loss: 0.0273 - acc: 0.9861 - val_loss: 0.2571 - val_acc: 0.7895\n",
      "Epoch 226/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0194 - acc: 1.000 - 0s 957us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.2376 - val_acc: 0.7895\n",
      "Epoch 227/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0131 - acc: 1.000 - ETA: 0s - loss: 0.0322 - acc: 0.985 - 0s 1ms/step - loss: 0.0313 - acc: 0.9861 - val_loss: 0.2485 - val_acc: 0.7895\n",
      "Epoch 228/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 8.1160e-04 - acc: 1.000 - ETA: 0s - loss: 0.0257 - acc: 1.0000    - 0s 1ms/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.8421\n",
      "Epoch 229/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.0414e-04 - acc: 1.000 - 0s 1ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.2355 - val_acc: 0.7895\n",
      "Epoch 230/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0224 - acc: 1.000 - 0s 1ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.2729 - val_acc: 0.7895\n",
      "Epoch 231/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1554 - acc: 0.900 - 0s 900us/step - loss: 0.0290 - acc: 0.9861 - val_loss: 0.2916 - val_acc: 0.7895\n",
      "Epoch 232/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0140 - acc: 1.000 - 0s 1ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3011 - val_acc: 0.7895\n",
      "Epoch 233/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.000 - 0s 1ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.2505 - val_acc: 0.7895\n",
      "Epoch 234/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.6891e-04 - acc: 1.000 - 0s 962us/step - loss: 0.0671 - acc: 0.9861 - val_loss: 0.3590 - val_acc: 0.7895\n",
      "Epoch 235/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0252 - acc: 1.000 - 0s 1ms/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.3529 - val_acc: 0.7895\n",
      "Epoch 236/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0077 - acc: 1.000 - ETA: 0s - loss: 0.0420 - acc: 0.971 - 0s 1ms/step - loss: 0.0408 - acc: 0.9722 - val_loss: 0.3721 - val_acc: 0.7895\n",
      "Epoch 237/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0572 - acc: 1.000 - ETA: 0s - loss: 0.0236 - acc: 0.983 - 0s 1ms/step - loss: 0.0288 - acc: 0.9861 - val_loss: 0.3695 - val_acc: 0.7895\n",
      "Epoch 238/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0125 - acc: 1.000 - 0s 1ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3345 - val_acc: 0.7895\n",
      "Epoch 239/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0127 - acc: 1.000 - 0s 949us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3147 - val_acc: 0.7895\n",
      "Epoch 240/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.6126e-04 - acc: 1.000 - ETA: 0s - loss: 0.0131 - acc: 1.0000    - 0s 1ms/step - loss: 0.0364 - acc: 0.9861 - val_loss: 0.2954 - val_acc: 0.7895\n",
      "Epoch 241/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0291 - acc: 0.985 - 0s 1ms/step - loss: 0.0284 - acc: 0.9861 - val_loss: 0.3648 - val_acc: 0.7895\n",
      "Epoch 242/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.000 - 0s 846us/step - loss: 0.0858 - acc: 0.9722 - val_loss: 0.3739 - val_acc: 0.7895\n",
      "Epoch 243/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0233 - acc: 1.000 - ETA: 0s - loss: 0.0176 - acc: 1.000 - 0s 1ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.3442 - val_acc: 0.7895\n",
      "Epoch 244/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.4426e-04 - acc: 1.000 - ETA: 0s - loss: 0.0049 - acc: 1.0000    - 0s 1ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.2611 - val_acc: 0.7895\n",
      "Epoch 245/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0058 - acc: 1.000 - 0s 860us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.2141 - val_acc: 0.8421\n",
      "Epoch 246/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0040 - acc: 1.000 - 0s 894us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.2474 - val_acc: 0.7895\n",
      "Epoch 247/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0280 - acc: 1.000 - ETA: 0s - loss: 0.0157 - acc: 1.000 - 0s 1ms/step - loss: 0.0525 - acc: 0.9861 - val_loss: 0.3459 - val_acc: 0.7895\n",
      "Epoch 248/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0236 - acc: 1.000 - 0s 999us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.3316 - val_acc: 0.7895\n",
      "Epoch 249/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0060 - acc: 1.000 - 0s 1ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.2968 - val_acc: 0.7895\n",
      "Epoch 250/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 1ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.2942 - val_acc: 0.7895\n",
      "Epoch 251/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0235 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - 0s 1ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.2694 - val_acc: 0.7895\n",
      "Epoch 252/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - 0s 1ms/step - loss: 0.0371 - acc: 0.9722 - val_loss: 0.4001 - val_acc: 0.7895\n",
      "Epoch 253/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.5853e-04 - acc: 1.000 - ETA: 0s - loss: 0.0181 - acc: 1.0000    - 0s 1ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.3948 - val_acc: 0.7895\n",
      "Epoch 254/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0880 - acc: 1.000 - ETA: 0s - loss: 0.0191 - acc: 1.000 - 0s 1ms/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.3977 - val_acc: 0.7895\n",
      "Epoch 255/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 868us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.2610 - val_acc: 0.7895\n",
      "Epoch 256/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0308 - acc: 1.000 - 0s 1ms/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.3341 - val_acc: 0.7895\n",
      "Epoch 257/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.1733e-04 - acc: 1.000 - ETA: 0s - loss: 0.0134 - acc: 1.0000    - 0s 2ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.3745 - val_acc: 0.7895\n",
      "Epoch 258/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - 0s 1ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.2879 - val_acc: 0.7895\n",
      "Epoch 259/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0324 - acc: 1.000 - ETA: 0s - loss: 0.0435 - acc: 0.985 - 0s 1ms/step - loss: 0.0423 - acc: 0.9861 - val_loss: 0.3509 - val_acc: 0.7895\n",
      "Epoch 260/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2662 - acc: 0.800 - 0s 868us/step - loss: 0.0718 - acc: 0.9583 - val_loss: 0.4172 - val_acc: 0.7895\n",
      "Epoch 261/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 0.0081 - acc: 1.000 - ETA: 0s - loss: 0.0116 - acc: 1.000 - 0s 1ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3916 - val_acc: 0.7895\n",
      "Epoch 262/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0064 - acc: 1.000 - 0s 1ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.3635 - val_acc: 0.7895\n",
      "Epoch 263/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0295 - acc: 1.000 - ETA: 0s - loss: 0.0274 - acc: 0.985 - 0s 1ms/step - loss: 0.0272 - acc: 0.9861 - val_loss: 0.3490 - val_acc: 0.7895\n",
      "Epoch 264/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1229 - acc: 0.900 - ETA: 0s - loss: 0.0412 - acc: 0.985 - 0s 986us/step - loss: 0.0401 - acc: 0.9861 - val_loss: 0.4175 - val_acc: 0.7895\n",
      "Epoch 265/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.5973e-04 - acc: 1.000 - ETA: 0s - loss: 0.0131 - acc: 1.0000    - 0s 1ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3882 - val_acc: 0.7895\n",
      "Epoch 266/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.000 - 0s 782us/step - loss: 0.0214 - acc: 0.9861 - val_loss: 0.3414 - val_acc: 0.7895\n",
      "Epoch 267/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0226 - acc: 1.000 - 0s 1ms/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.3298 - val_acc: 0.7895\n",
      "Epoch 268/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.000 - 0s 888us/step - loss: 0.0538 - acc: 0.9722 - val_loss: 0.3918 - val_acc: 0.7895\n",
      "Epoch 269/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0257 - acc: 1.000 - ETA: 0s - loss: 0.0310 - acc: 0.985 - 0s 1ms/step - loss: 0.0301 - acc: 0.9861 - val_loss: 0.4325 - val_acc: 0.7895\n",
      "Epoch 270/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0258 - acc: 1.000 - 0s 879us/step - loss: 0.0191 - acc: 0.9861 - val_loss: 0.3364 - val_acc: 0.7895\n",
      "Epoch 271/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0044 - acc: 1.000 - 0s 868us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.2696 - val_acc: 0.7895\n",
      "Epoch 272/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0246 - acc: 1.000 - 0s 868us/step - loss: 0.0284 - acc: 0.9861 - val_loss: 0.3512 - val_acc: 0.7895\n",
      "Epoch 273/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.000 - 0s 868us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3642 - val_acc: 0.7895\n",
      "Epoch 274/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0452 - acc: 1.000 - 0s 1ms/step - loss: 0.0394 - acc: 0.9861 - val_loss: 0.4371 - val_acc: 0.7895\n",
      "Epoch 275/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0391 - acc: 1.000 - 0s 954us/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.4446 - val_acc: 0.7895\n",
      "Epoch 276/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0109 - acc: 1.000 - 0s 1ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.4104 - val_acc: 0.7895\n",
      "Epoch 277/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0488 - acc: 1.000 - 0s 967us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.7895\n",
      "Epoch 278/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0396 - acc: 1.000 - 0s 1ms/step - loss: 0.0309 - acc: 0.9861 - val_loss: 0.5288 - val_acc: 0.7895\n",
      "Epoch 279/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0760 - acc: 1.000 - 0s 1ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.3878 - val_acc: 0.7895\n",
      "Epoch 280/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.7490e-04 - acc: 1.000 - ETA: 0s - loss: 0.0157 - acc: 1.0000    - 0s 1ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.4273 - val_acc: 0.7895\n",
      "Epoch 281/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.7769e-04 - acc: 1.000 - ETA: 0s - loss: 0.0126 - acc: 1.0000    - 0s 1ms/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.4686 - val_acc: 0.7895\n",
      "Epoch 282/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0095 - acc: 1.000 - 0s 845us/step - loss: 0.0310 - acc: 0.9861 - val_loss: 0.3830 - val_acc: 0.7895\n",
      "Epoch 283/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - 0s 868us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.7895\n",
      "Epoch 284/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.6060e-04 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.0000    - 0s 1ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.2982 - val_acc: 0.7895\n",
      "Epoch 285/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - 0s 768us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3460 - val_acc: 0.7895\n",
      "Epoch 286/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 9.5458e-04 - acc: 1.000 - ETA: 0s - loss: 0.0144 - acc: 1.0000    - 0s 1ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.3914 - val_acc: 0.7895\n",
      "Epoch 287/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0212 - acc: 1.000 - 0s 967us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.3746 - val_acc: 0.7895\n",
      "Epoch 288/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.9221e-04 - acc: 1.000 - ETA: 0s - loss: 0.0247 - acc: 0.9857    - 0s 1ms/step - loss: 0.0240 - acc: 0.9861 - val_loss: 0.4704 - val_acc: 0.7895\n",
      "Epoch 289/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0455 - acc: 1.000 - ETA: 0s - loss: 0.0261 - acc: 1.000 - 0s 1ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.4603 - val_acc: 0.7895\n",
      "Epoch 290/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.4895e-04 - acc: 1.000 - ETA: 0s - loss: 0.0401 - acc: 0.9857    - 0s 1ms/step - loss: 0.0391 - acc: 0.9861 - val_loss: 0.4989 - val_acc: 0.7895\n",
      "Epoch 291/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0108 - acc: 1.000 - ETA: 0s - loss: 0.0374 - acc: 0.971 - 0s 1ms/step - loss: 0.0367 - acc: 0.9722 - val_loss: 0.3458 - val_acc: 0.7895\n",
      "Epoch 292/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.8867e-04 - acc: 1.000 - 0s 868us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3119 - val_acc: 0.7895\n",
      "Epoch 293/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0437 - acc: 1.000 - 0s 868us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.2720 - val_acc: 0.8421\n",
      "Epoch 294/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0236 - acc: 1.000 - ETA: 0s - loss: 0.0094 - acc: 1.000 - 0s 1ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3252 - val_acc: 0.7895\n",
      "Epoch 295/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 9.4502e-04 - acc: 1.000 - 0s 911us/step - loss: 0.0161 - acc: 0.9861 - val_loss: 0.4248 - val_acc: 0.7895\n",
      "Epoch 296/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0072 - acc: 1.000 - 0s 868us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.3918 - val_acc: 0.7895\n",
      "Epoch 297/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.000 - 0s 868us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.3824 - val_acc: 0.7895\n",
      "Epoch 298/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 8.5244e-04 - acc: 1.000 - 0s 1ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.2978 - val_acc: 0.8421\n",
      "Epoch 299/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0053 - acc: 1.000 - ETA: 0s - loss: 0.0572 - acc: 0.985 - 0s 1ms/step - loss: 0.0556 - acc: 0.9861 - val_loss: 0.4551 - val_acc: 0.7895\n",
      "Epoch 300/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0033 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - 0s 1ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4338 - val_acc: 0.7895\n",
      "Epoch 301/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0086 - acc: 1.000 - 0s 944us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4525 - val_acc: 0.7895\n",
      "Epoch 302/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.8756e-04 - acc: 1.000 - 0s 868us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.5218 - val_acc: 0.7895\n",
      "Epoch 303/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.000 - 0s 1ms/step - loss: 0.0235 - acc: 0.9861 - val_loss: 0.5987 - val_acc: 0.7895\n",
      "Epoch 304/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0244 - acc: 1.000 - 0s 1ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.5015 - val_acc: 0.7895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0090 - acc: 1.000 - 0s 1ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4438 - val_acc: 0.7895\n",
      "Epoch 306/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0160 - acc: 0.985 - 0s 917us/step - loss: 0.0156 - acc: 0.9861 - val_loss: 0.3260 - val_acc: 0.7895\n",
      "Epoch 307/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.000 - 0s 868us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.2834 - val_acc: 0.8421\n",
      "Epoch 308/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2593 - acc: 0.900 - 0s 868us/step - loss: 0.0418 - acc: 0.9861 - val_loss: 0.3835 - val_acc: 0.7895\n",
      "Epoch 309/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.5417e-04 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 1.0000    - 0s 1ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3791 - val_acc: 0.7895\n",
      "Epoch 310/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0073 - acc: 1.000 - ETA: 0s - loss: 0.0117 - acc: 1.000 - 0s 1ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3782 - val_acc: 0.7895\n",
      "Epoch 311/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.9997e-04 - acc: 1.000 - ETA: 0s - loss: 0.0147 - acc: 1.0000    - 0s 1ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.2805 - val_acc: 0.8421\n",
      "Epoch 312/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.000 - 0s 984us/step - loss: 0.0188 - acc: 0.9861 - val_loss: 0.3352 - val_acc: 0.7895\n",
      "Epoch 313/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0128 - acc: 1.000 - 0s 998us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3939 - val_acc: 0.7895\n",
      "Epoch 314/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.000 - 0s 902us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8421\n",
      "Epoch 315/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0163 - acc: 1.000 - 0s 967us/step - loss: 0.0368 - acc: 0.9722 - val_loss: 0.5821 - val_acc: 0.7895\n",
      "Epoch 316/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.8975e-04 - acc: 1.000 - 0s 976us/step - loss: 0.0244 - acc: 0.9861 - val_loss: 0.4571 - val_acc: 0.7895\n",
      "Epoch 317/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 868us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.4625 - val_acc: 0.7895\n",
      "Epoch 318/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.0801e-04 - acc: 1.000 - 0s 1ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4739 - val_acc: 0.7895\n",
      "Epoch 319/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0938 - acc: 0.900 - 0s 1ms/step - loss: 0.0357 - acc: 0.9722 - val_loss: 0.4237 - val_acc: 0.7895\n",
      "Epoch 320/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 1ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4580 - val_acc: 0.7895\n",
      "Epoch 321/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - 0s 985us/step - loss: 0.0359 - acc: 0.9861 - val_loss: 0.3210 - val_acc: 0.7895\n",
      "Epoch 322/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1207 - acc: 0.900 - 0s 944us/step - loss: 0.0210 - acc: 0.9861 - val_loss: 0.3317 - val_acc: 0.7895\n",
      "Epoch 323/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.2985e-04 - acc: 1.000 - 0s 1ms/step - loss: 0.0178 - acc: 0.9861 - val_loss: 0.3687 - val_acc: 0.7895\n",
      "Epoch 324/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0040 - acc: 1.000 - 0s 902us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.3658 - val_acc: 0.7895\n",
      "Epoch 325/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - 0s 868us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.2341 - val_acc: 0.8421\n",
      "Epoch 326/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - 0s 2ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2368 - val_acc: 0.8421\n",
      "Epoch 327/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 8.8876e-04 - acc: 1.000 - ETA: 0s - loss: 0.0065 - acc: 1.0000    - 0s 1ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.2668 - val_acc: 0.8421\n",
      "Epoch 328/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0371 - acc: 0.983 - 0s 1ms/step - loss: 0.0486 - acc: 0.9722 - val_loss: 0.4371 - val_acc: 0.7895\n",
      "Epoch 329/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0063 - acc: 1.000 - 0s 1ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4097 - val_acc: 0.7895\n",
      "Epoch 330/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0076 - acc: 1.000 - ETA: 0s - loss: 0.0054 - acc: 1.000 - 0s 2ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4250 - val_acc: 0.7895\n",
      "Epoch 331/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.2138e-04 - acc: 1.000 - ETA: 0s - loss: 0.0127 - acc: 1.0000    - 0s 2ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4205 - val_acc: 0.7895\n",
      "Epoch 332/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1204 - acc: 0.900 - ETA: 0s - loss: 0.0253 - acc: 0.983 - 0s 1ms/step - loss: 0.0454 - acc: 0.9722 - val_loss: 0.4193 - val_acc: 0.7895\n",
      "Epoch 333/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0119 - acc: 1.000 - ETA: 0s - loss: 0.0070 - acc: 1.000 - 0s 1ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.3608 - val_acc: 0.7895\n",
      "Epoch 334/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3464 - val_acc: 0.7895\n",
      "Epoch 335/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.5429e-04 - acc: 1.000 - ETA: 0s - loss: 0.0092 - acc: 1.0000    - 0s 2ms/step - loss: 0.0204 - acc: 0.9861 - val_loss: 0.3695 - val_acc: 0.7895\n",
      "Epoch 336/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 9.7354e-04 - acc: 1.000 - 0s 986us/step - loss: 0.0311 - acc: 0.9861 - val_loss: 0.5000 - val_acc: 0.7895\n",
      "Epoch 337/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1858e-04 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 1.0000    - 0s 1ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.4510 - val_acc: 0.7895\n",
      "Epoch 338/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.3218e-04 - acc: 1.000 - ETA: 0s - loss: 0.0033 - acc: 1.0000    - 0s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4115 - val_acc: 0.7895\n",
      "Epoch 339/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.2112e-05 - acc: 1.000 - ETA: 0s - loss: 0.0047 - acc: 1.0000    - 0s 1ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3947 - val_acc: 0.7895\n",
      "Epoch 340/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0054 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.000 - 0s 2ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4725 - val_acc: 0.7895\n",
      "Epoch 341/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0117 - acc: 1.000 - ETA: 0s - loss: 0.0447 - acc: 0.980 - 0s 2ms/step - loss: 0.0321 - acc: 0.9861 - val_loss: 0.4727 - val_acc: 0.7895\n",
      "Epoch 342/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0466 - acc: 1.000 - ETA: 0s - loss: 0.0267 - acc: 0.983 - 0s 1ms/step - loss: 0.0263 - acc: 0.9861 - val_loss: 0.4571 - val_acc: 0.7895\n",
      "Epoch 343/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.5221e-04 - acc: 1.000 - ETA: 0s - loss: 0.0057 - acc: 1.0000    - 0s 1ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.2764 - val_acc: 0.7895\n",
      "Epoch 344/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0090 - acc: 1.000 - 0s 1ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3462 - val_acc: 0.7895\n",
      "Epoch 345/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.2966e-04 - acc: 1.000 - ETA: 0s - loss: 0.0101 - acc: 1.0000    - 0s 1ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3585 - val_acc: 0.7895\n",
      "Epoch 346/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 0.1476 - acc: 0.900 - ETA: 0s - loss: 0.0403 - acc: 0.983 - 0s 1ms/step - loss: 0.0338 - acc: 0.9861 - val_loss: 0.3700 - val_acc: 0.7895\n",
      "Epoch 347/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0199 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - 0s 2ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4096 - val_acc: 0.7895\n",
      "Epoch 348/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - 0s 1ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.3830 - val_acc: 0.7895\n",
      "Epoch 349/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0093 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - 0s 1ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5097 - val_acc: 0.7895\n",
      "Epoch 350/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 6.0255e-04 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.0000    - 0s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4537 - val_acc: 0.7895\n",
      "Epoch 351/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - 0s 1ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.3263 - val_acc: 0.7895\n",
      "Epoch 352/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0104 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - 0s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.3229 - val_acc: 0.7895\n",
      "Epoch 353/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.4476e-04 - acc: 1.000 - ETA: 0s - loss: 0.0027 - acc: 1.0000    - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2950 - val_acc: 0.7895\n",
      "Epoch 354/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.6241e-04 - acc: 1.000 - ETA: 0s - loss: 0.0053 - acc: 1.0000    - 0s 1ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3747 - val_acc: 0.7895\n",
      "Epoch 355/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0222 - acc: 1.000 - ETA: 0s - loss: 0.0494 - acc: 0.983 - 0s 1ms/step - loss: 0.0412 - acc: 0.9861 - val_loss: 0.5316 - val_acc: 0.7895\n",
      "Epoch 356/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0559 - acc: 1.000 - ETA: 0s - loss: 0.0287 - acc: 0.985 - 0s 1ms/step - loss: 0.0279 - acc: 0.9861 - val_loss: 0.6250 - val_acc: 0.7895\n",
      "Epoch 357/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.8219e-04 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.0000    - 0s 1ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5323 - val_acc: 0.7895\n",
      "Epoch 358/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0087 - acc: 1.000 - ETA: 0s - loss: 0.0141 - acc: 1.000 - 0s 1ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.5885 - val_acc: 0.7895\n",
      "Epoch 359/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.8537e-04 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.0000    - 0s 1ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5308 - val_acc: 0.7895\n",
      "Epoch 360/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0583 - acc: 1.000 - ETA: 0s - loss: 0.0155 - acc: 1.000 - 0s 1ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.6006 - val_acc: 0.7895\n",
      "Epoch 361/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0156 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 1.000 - 0s 1ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.6205 - val_acc: 0.7895\n",
      "Epoch 362/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1725 - acc: 0.900 - ETA: 0s - loss: 0.0348 - acc: 0.980 - 0s 2ms/step - loss: 0.0269 - acc: 0.9861 - val_loss: 0.4575 - val_acc: 0.7895\n",
      "Epoch 363/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.9916e-04 - acc: 1.000 - ETA: 0s - loss: 0.0355 - acc: 0.9833    - 0s 1ms/step - loss: 0.0305 - acc: 0.9861 - val_loss: 0.5397 - val_acc: 0.7895\n",
      "Epoch 364/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0047 - acc: 1.000 - 0s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4947 - val_acc: 0.7895\n",
      "Epoch 365/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0065 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - 0s 1ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3743 - val_acc: 0.7895\n",
      "Epoch 366/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0084 - acc: 1.000 - ETA: 0s - loss: 0.0253 - acc: 0.983 - 0s 1ms/step - loss: 0.0211 - acc: 0.9861 - val_loss: 0.5000 - val_acc: 0.7895\n",
      "Epoch 367/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.6703e-04 - acc: 1.000 - ETA: 0s - loss: 0.0109 - acc: 1.0000    - 0s 1ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3819 - val_acc: 0.7895\n",
      "Epoch 368/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0063 - acc: 1.000 - ETA: 0s - loss: 0.0122 - acc: 1.000 - 0s 2ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4568 - val_acc: 0.7895\n",
      "Epoch 369/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0099 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.000 - 0s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4241 - val_acc: 0.7895\n",
      "Epoch 370/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0064 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - 0s 2ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.3270 - val_acc: 0.7895\n",
      "Epoch 371/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0305 - acc: 1.000 - ETA: 0s - loss: 0.0227 - acc: 0.983 - 0s 1ms/step - loss: 0.0239 - acc: 0.9861 - val_loss: 0.3753 - val_acc: 0.7895\n",
      "Epoch 372/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.4707e-05 - acc: 1.000 - ETA: 0s - loss: 0.0024 - acc: 1.0000    - 0s 2ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.3525 - val_acc: 0.7895\n",
      "Epoch 373/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.000 - ETA: 0s - loss: 0.0544 - acc: 0.980 - 0s 2ms/step - loss: 0.0378 - acc: 0.9861 - val_loss: 0.4876 - val_acc: 0.7895\n",
      "Epoch 374/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0246 - acc: 1.000 - ETA: 0s - loss: 0.0220 - acc: 1.000 - 0s 1ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6552 - val_acc: 0.7895\n",
      "Epoch 375/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.7940e-04 - acc: 1.000 - ETA: 0s - loss: 0.0159 - acc: 1.0000    - 0s 1ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.4587 - val_acc: 0.7895\n",
      "Epoch 376/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0197 - acc: 1.000 - 0s 1ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.5797 - val_acc: 0.7895\n",
      "Epoch 377/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0243 - acc: 1.000 - ETA: 0s - loss: 0.0089 - acc: 1.000 - 0s 1ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5780 - val_acc: 0.7895\n",
      "Epoch 378/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 9.7623e-05 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 1.0000    - 0s 1ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5755 - val_acc: 0.7895\n",
      "Epoch 379/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.9270e-04 - acc: 1.000 - ETA: 0s - loss: 0.0183 - acc: 1.0000    - 0s 1ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6693 - val_acc: 0.7895\n",
      "Epoch 380/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0196 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 1.000 - 0s 1ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.7895\n",
      "Epoch 381/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0124 - acc: 1.000 - 0s 1ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.6008 - val_acc: 0.7895\n",
      "Epoch 382/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0092 - acc: 1.000 - ETA: 0s - loss: 0.0109 - acc: 1.000 - 0s 1ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.6620 - val_acc: 0.7895\n",
      "Epoch 383/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0054 - acc: 1.000 - 0s 1ms/step - loss: 0.0172 - acc: 0.9861 - val_loss: 0.4571 - val_acc: 0.7895\n",
      "Epoch 384/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0089 - acc: 1.000 - 0s 1ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4649 - val_acc: 0.7895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 8.0407e-05 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.0000    - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4413 - val_acc: 0.7895\n",
      "Epoch 386/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.6965e-04 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.0000    - ETA: 0s - loss: 0.0047 - acc: 1.000 - 0s 2ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3547 - val_acc: 0.7895\n",
      "Epoch 387/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.8826e-04 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.0000    - 0s 1ms/step - loss: 0.0169 - acc: 0.9861 - val_loss: 0.4658 - val_acc: 0.7895\n",
      "Epoch 388/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.000 - ETA: 0s - loss: 0.0144 - acc: 1.000 - 0s 1ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.5655 - val_acc: 0.7895\n",
      "Epoch 389/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 8.1011e-04 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.0000    - 0s 1ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5097 - val_acc: 0.7895\n",
      "Epoch 390/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.7456e-04 - acc: 1.000 - ETA: 0s - loss: 0.0204 - acc: 1.0000    - 0s 2ms/step - loss: 0.0567 - acc: 0.9861 - val_loss: 0.4947 - val_acc: 0.7895\n",
      "Epoch 391/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0126 - acc: 1.000 - 0s 1ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.5727 - val_acc: 0.7895\n",
      "Epoch 392/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.5243e-04 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.0000    - 0s 1ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.6024 - val_acc: 0.7895\n",
      "Epoch 393/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.9817e-04 - acc: 1.000 - ETA: 0s - loss: 0.0145 - acc: 1.0000    - 0s 2ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.6310 - val_acc: 0.7895\n",
      "Epoch 394/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0047 - acc: 1.000 - ETA: 0s - loss: 0.0064 - acc: 1.000 - 0s 1ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5880 - val_acc: 0.7895\n",
      "Epoch 395/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.0586e-04 - acc: 1.000 - ETA: 0s - loss: 0.0245 - acc: 0.9833    - 0s 1ms/step - loss: 0.0212 - acc: 0.9861 - val_loss: 0.6507 - val_acc: 0.7895\n",
      "Epoch 396/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.1143e-04 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.0000    - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6068 - val_acc: 0.7895\n",
      "Epoch 397/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0047 - acc: 1.000 - ETA: 0s - loss: 0.0045 - acc: 1.000 - 0s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5149 - val_acc: 0.7895\n",
      "Epoch 398/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - 0s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5236 - val_acc: 0.7895\n",
      "Epoch 399/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0219 - acc: 0.985 - 0s 1ms/step - loss: 0.0219 - acc: 0.9861 - val_loss: 0.6236 - val_acc: 0.7895\n",
      "Epoch 400/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0052 - acc: 1.000 - 0s 1ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5528 - val_acc: 0.7895\n",
      "Epoch 401/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0591 - acc: 1.000 - ETA: 0s - loss: 0.0126 - acc: 1.000 - 0s 1ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5563 - val_acc: 0.7895\n",
      "Epoch 402/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1145e-04 - acc: 1.000 - ETA: 0s - loss: 0.0115 - acc: 1.0000    - 0s 1ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.7895\n",
      "Epoch 403/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0073 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - 0s 1ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4412 - val_acc: 0.7895\n",
      "Epoch 404/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0289 - acc: 0.983 - 0s 1ms/step - loss: 0.0242 - acc: 0.9861 - val_loss: 0.3931 - val_acc: 0.7895\n",
      "Epoch 405/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.3696e-04 - acc: 1.000 - ETA: 0s - loss: 0.0038 - acc: 1.0000    - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.3538 - val_acc: 0.7895\n",
      "Epoch 406/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.7360e-04 - acc: 1.000 - ETA: 0s - loss: 0.0154 - acc: 0.9833    - 0s 1ms/step - loss: 0.0138 - acc: 0.9861 - val_loss: 0.4228 - val_acc: 0.7895\n",
      "Epoch 407/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0037e-04 - acc: 1.000 - ETA: 0s - loss: 0.0138 - acc: 1.0000    - 0s 1ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3882 - val_acc: 0.7895\n",
      "Epoch 408/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.6627e-04 - acc: 1.000 - ETA: 0s - loss: 0.0070 - acc: 1.0000    - 0s 1ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4497 - val_acc: 0.7895\n",
      "Epoch 409/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 0s - loss: 0.0050 - acc: 1.000 - 0s 2ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3897 - val_acc: 0.7895\n",
      "Epoch 410/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.3182e-04 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.0000    - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3824 - val_acc: 0.7895\n",
      "Epoch 411/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - 0s 1ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.3659 - val_acc: 0.7895\n",
      "Epoch 412/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1582e-04 - acc: 1.000 - ETA: 0s - loss: 0.0062 - acc: 1.0000    - 0s 1ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.3541 - val_acc: 0.7895\n",
      "Epoch 413/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0202 - acc: 1.000 - ETA: 0s - loss: 0.0338 - acc: 0.983 - 0s 1ms/step - loss: 0.0297 - acc: 0.9861 - val_loss: 0.4160 - val_acc: 0.7895\n",
      "Epoch 414/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0054 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.000 - 0s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3847 - val_acc: 0.7895\n",
      "Epoch 415/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 9.1676e-04 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.0000    - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.7895\n",
      "Epoch 416/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0078 - acc: 1.000 - ETA: 0s - loss: 0.0271 - acc: 0.983 - 0s 1ms/step - loss: 0.0232 - acc: 0.9861 - val_loss: 0.5174 - val_acc: 0.7895\n",
      "Epoch 417/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0057 - acc: 1.000 - ETA: 0s - loss: 0.0397 - acc: 0.975 - ETA: 0s - loss: 0.0236 - acc: 0.985 - 0s 2ms/step - loss: 0.0230 - acc: 0.9861 - val_loss: 0.6525 - val_acc: 0.7895\n",
      "Epoch 418/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.0372e-04 - acc: 1.000 - ETA: 0s - loss: 0.0059 - acc: 1.0000    - 0s 1ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5728 - val_acc: 0.7895\n",
      "Epoch 419/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0143 - acc: 1.000 - 0s 1ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.7895\n",
      "Epoch 420/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0079 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - 0s 1ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5227 - val_acc: 0.7895\n",
      "Epoch 421/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1685 - acc: 0.900 - ETA: 0s - loss: 0.0297 - acc: 0.983 - 0s 1ms/step - loss: 0.0287 - acc: 0.9861 - val_loss: 0.6011 - val_acc: 0.7895\n",
      "Epoch 422/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0110 - acc: 1.000 - ETA: 0s - loss: 0.0074 - acc: 1.000 - 0s 2ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5851 - val_acc: 0.7895\n",
      "Epoch 423/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0142 - acc: 1.000 - 0s 1ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.6688 - val_acc: 0.7895\n",
      "Epoch 424/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.6190e-05 - acc: 1.000 - ETA: 0s - loss: 0.0083 - acc: 1.0000    - 0s 1ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.6929 - val_acc: 0.7895\n",
      "Epoch 425/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0440 - acc: 1.000 - ETA: 0s - loss: 0.0073 - acc: 1.000 - 0s 1ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.6080 - val_acc: 0.7895\n",
      "Epoch 426/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0113 - acc: 1.000 - ETA: 0s - loss: 0.0047 - acc: 1.000 - 0s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5471 - val_acc: 0.7895\n",
      "Epoch 427/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.7842e-04 - acc: 1.000 - ETA: 0s - loss: 0.0023 - acc: 1.0000    - 0s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5178 - val_acc: 0.7895\n",
      "Epoch 428/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.2218e-04 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.0000    - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5727 - val_acc: 0.7895\n",
      "Epoch 429/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0688 - acc: 1.000 - ETA: 0s - loss: 0.0234 - acc: 1.000 - 0s 1ms/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.5836 - val_acc: 0.7895\n",
      "Epoch 430/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.9983e-04 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.0000    - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5750 - val_acc: 0.7895\n",
      "Epoch 431/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.9694e-05 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.0000    - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5269 - val_acc: 0.7895\n",
      "Epoch 432/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0547 - acc: 1.000 - ETA: 0s - loss: 0.0220 - acc: 1.000 - 0s 1ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.5715 - val_acc: 0.7895\n",
      "Epoch 433/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0226 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 1.000 - 0s 1ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5208 - val_acc: 0.7895\n",
      "Epoch 434/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0032 - acc: 1.000 - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5576 - val_acc: 0.7895\n",
      "Epoch 435/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.4947 - val_acc: 0.7895\n",
      "Epoch 436/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2374e-05 - acc: 1.000 - ETA: 0s - loss: 0.0344 - acc: 0.9833    - 0s 1ms/step - loss: 0.0291 - acc: 0.9861 - val_loss: 0.3982 - val_acc: 0.7895\n",
      "Epoch 437/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1194 - acc: 0.900 - ETA: 0s - loss: 0.0251 - acc: 0.985 - 0s 1ms/step - loss: 0.0244 - acc: 0.9861 - val_loss: 0.5632 - val_acc: 0.7895\n",
      "Epoch 438/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.9318e-05 - acc: 1.000 - ETA: 0s - loss: 0.0061 - acc: 1.0000    - 0s 1ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4206 - val_acc: 0.7895\n",
      "Epoch 439/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.8567e-04 - acc: 1.000 - ETA: 0s - loss: 0.0105 - acc: 1.0000    - 0s 1ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5382 - val_acc: 0.7895\n",
      "Epoch 440/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.4539e-04 - acc: 1.000 - ETA: 0s - loss: 0.0171 - acc: 0.9857    - 0s 1ms/step - loss: 0.0166 - acc: 0.9861 - val_loss: 0.7411 - val_acc: 0.7895\n",
      "Epoch 441/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0380 - acc: 1.000 - ETA: 0s - loss: 0.0079 - acc: 1.000 - 0s 1ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.6191 - val_acc: 0.7895\n",
      "Epoch 442/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.9456e-04 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.0000    - 0s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5795 - val_acc: 0.7895\n",
      "Epoch 443/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.6578e-04 - acc: 1.000 - ETA: 0s - loss: 0.0116 - acc: 1.0000    - 0s 2ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4306 - val_acc: 0.7895\n",
      "Epoch 444/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.8076e-04 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.0000    - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3985 - val_acc: 0.7895\n",
      "Epoch 445/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - 0s 1ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5729 - val_acc: 0.7895\n",
      "Epoch 446/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5074 - val_acc: 0.7895\n",
      "Epoch 447/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0259 - acc: 0.985 - 0s 1ms/step - loss: 0.0274 - acc: 0.9861 - val_loss: 0.6865 - val_acc: 0.7895\n",
      "Epoch 448/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0121 - acc: 1.000 - ETA: 0s - loss: 0.0047 - acc: 1.000 - 0s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 0.7895\n",
      "Epoch 449/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0163 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - 0s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5680 - val_acc: 0.7895\n",
      "Epoch 450/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0246 - acc: 1.000 - ETA: 0s - loss: 0.0060 - acc: 1.000 - 0s 1ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4428 - val_acc: 0.7895\n",
      "Epoch 451/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0239 - acc: 0.985 - 0s 1ms/step - loss: 0.0232 - acc: 0.9861 - val_loss: 0.4934 - val_acc: 0.7895\n",
      "Epoch 452/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.7895\n",
      "Epoch 453/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.6455e-04 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.0000    - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4669 - val_acc: 0.7895\n",
      "Epoch 454/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 1.000 - 0s 1ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.2889 - val_acc: 0.8421\n",
      "Epoch 455/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.6380e-04 - acc: 1.000 - ETA: 0s - loss: 9.4128e-04 - acc: 1.000 - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2839 - val_acc: 0.8421\n",
      "Epoch 456/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.000 - ETA: 0s - loss: 0.0261 - acc: 0.985 - 0s 1ms/step - loss: 0.0254 - acc: 0.9861 - val_loss: 0.3724 - val_acc: 0.7895\n",
      "Epoch 457/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3157 - val_acc: 0.7895\n",
      "Epoch 458/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.0562e-04 - acc: 1.000 - ETA: 0s - loss: 7.4946e-04 - acc: 1.000 - 0s 1ms/step - loss: 7.2876e-04 - acc: 1.0000 - val_loss: 0.3124 - val_acc: 0.7895\n",
      "Epoch 459/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.5167e-04 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.0000    - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3579 - val_acc: 0.7895\n",
      "Epoch 460/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.3896e-04 - acc: 1.000 - ETA: 0s - loss: 9.0004e-04 - acc: 1.000 - 0s 1ms/step - loss: 8.7567e-04 - acc: 1.0000 - val_loss: 0.3793 - val_acc: 0.7895\n",
      "Epoch 461/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 3.9618e-04 - acc: 1.000 - ETA: 0s - loss: 0.0333 - acc: 0.9857    - 0s 1ms/step - loss: 0.0324 - acc: 0.9861 - val_loss: 0.6034 - val_acc: 0.7895\n",
      "Epoch 462/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 1.000 - 0s 1ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.6932 - val_acc: 0.7895\n",
      "Epoch 463/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.3995e-05 - acc: 1.000 - ETA: 0s - loss: 0.0232 - acc: 0.9833    - 0s 1ms/step - loss: 0.0194 - acc: 0.9861 - val_loss: 0.7782 - val_acc: 0.7895\n",
      "Epoch 464/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0480e-04 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.0000    - 0s 1ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.7037 - val_acc: 0.7895\n",
      "Epoch 465/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0093 - acc: 1.000 - ETA: 0s - loss: 0.0280 - acc: 0.983 - 0s 1ms/step - loss: 0.0235 - acc: 0.9861 - val_loss: 0.8057 - val_acc: 0.7895\n",
      "Epoch 466/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.5756e-05 - acc: 1.000 - ETA: 0s - loss: 0.0074 - acc: 1.0000    - 0s 1ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7130 - val_acc: 0.7895\n",
      "Epoch 467/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 1.000 - 0s 1ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.6151 - val_acc: 0.7895\n",
      "Epoch 468/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0087 - acc: 1.000 - 0s 1ms/step - loss: 0.0335 - acc: 0.9861 - val_loss: 0.7382 - val_acc: 0.7895\n",
      "Epoch 469/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.9097e-05 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.0000    - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7092 - val_acc: 0.7895\n",
      "Epoch 470/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0039 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6715 - val_acc: 0.7895\n",
      "Epoch 471/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0156 - acc: 1.000 - 0s 1ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.6338 - val_acc: 0.7895\n",
      "Epoch 472/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0068 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 1.000 - 0s 1ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.7201 - val_acc: 0.7895\n",
      "Epoch 473/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.0479e-05 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.0000    - 0s 1ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.7226 - val_acc: 0.7895\n",
      "Epoch 474/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 6.4821e-05 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.0000    - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.7895\n",
      "Epoch 475/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.3773e-05 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.0000    - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.7895\n",
      "Epoch 476/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.7966e-04 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.0000    - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 0.7895\n",
      "Epoch 477/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 9.1676e-04 - acc: 1.000 - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5701 - val_acc: 0.7895\n",
      "Epoch 478/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - 0s 1ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6976 - val_acc: 0.7895\n",
      "Epoch 479/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1267 - acc: 0.900 - ETA: 0s - loss: 0.0187 - acc: 0.985 - 0s 1ms/step - loss: 0.0182 - acc: 0.9861 - val_loss: 0.6871 - val_acc: 0.7895\n",
      "Epoch 480/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 6.9082e-04 - acc: 1.000 - ETA: 0s - loss: 0.0048 - acc: 1.0000    - 0s 1ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5651 - val_acc: 0.7895\n",
      "Epoch 481/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.5935e-04 - acc: 1.000 - ETA: 0s - loss: 7.3393e-04 - acc: 1.000 - 0s 1ms/step - loss: 9.7378e-04 - acc: 1.0000 - val_loss: 0.4606 - val_acc: 0.7895\n",
      "Epoch 482/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1397e-05 - acc: 1.000 - ETA: 0s - loss: 0.0380 - acc: 0.9833    - 0s 1ms/step - loss: 0.0319 - acc: 0.9861 - val_loss: 0.4037 - val_acc: 0.7895\n",
      "Epoch 483/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 9.8839e-04 - acc: 1.000 - ETA: 0s - loss: 0.0068 - acc: 1.0000    - 0s 1ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4318 - val_acc: 0.7895\n",
      "Epoch 484/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.4816e-04 - acc: 1.000 - ETA: 0s - loss: 0.0033 - acc: 1.0000    - 0s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4306 - val_acc: 0.7895\n",
      "Epoch 485/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - 0s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3913 - val_acc: 0.7895\n",
      "Epoch 486/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.8086e-04 - acc: 1.000 - ETA: 0s - loss: 0.0053 - acc: 1.0000    - 0s 1ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5379 - val_acc: 0.7895\n",
      "Epoch 487/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0184 - acc: 0.985 - 0s 1ms/step - loss: 0.0179 - acc: 0.9861 - val_loss: 0.6972 - val_acc: 0.7895\n",
      "Epoch 488/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.4740e-04 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.0000    - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6673 - val_acc: 0.7895\n",
      "Epoch 489/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0075 - acc: 1.000 - ETA: 0s - loss: 0.0027 - acc: 1.000 - 0s 1ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6489 - val_acc: 0.7895\n",
      "Epoch 490/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0039 - acc: 1.000 - ETA: 0s - loss: 0.0164 - acc: 0.985 - 0s 1ms/step - loss: 0.0159 - acc: 0.9861 - val_loss: 0.4763 - val_acc: 0.7895\n",
      "Epoch 491/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 8.5379e-05 - acc: 1.000 - ETA: 0s - loss: 0.0186 - acc: 0.9857    - 0s 1ms/step - loss: 0.0181 - acc: 0.9861 - val_loss: 0.6106 - val_acc: 0.7895\n",
      "Epoch 492/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6177 - val_acc: 0.7895\n",
      "Epoch 493/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0054 - acc: 1.000 - ETA: 0s - loss: 0.0093 - acc: 1.000 - 0s 1ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.7895\n",
      "Epoch 494/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - 0s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6929 - val_acc: 0.7895\n",
      "Epoch 495/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 9.1380e-05 - acc: 1.000 - ETA: 0s - loss: 0.0040 - acc: 1.0000    - 0s 1ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6113 - val_acc: 0.7895\n",
      "Epoch 496/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2696e-04 - acc: 1.000 - ETA: 0s - loss: 4.5653e-04 - acc: 1.000 - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4558 - val_acc: 0.7895\n",
      "Epoch 497/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.2551e-04 - acc: 1.000 - ETA: 0s - loss: 0.0033 - acc: 1.0000    - 0s 1ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5234 - val_acc: 0.7895\n",
      "Epoch 498/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.000 - ETA: 0s - loss: 0.0085 - acc: 1.000 - 0s 1ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4677 - val_acc: 0.7895\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - 0s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3450 - val_acc: 0.7895\n",
      "Epoch 500/500\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3984 - val_acc: 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:04:39 INFO     rasa_core.policies.keras_policy  - Done fitting keras policy model\n",
      "2020-03-21 23:04:39 INFO     rasa_core.agent  - Model directory ./models/dialogue exists and contains old model files. All files will be overwritten.\n",
      "2020-03-21 23:04:40 INFO     rasa_core.agent  - Persisted model to 'C:\\Users\\hung.td170078\\horoscope_bot\\models\\dialogue'\n"
     ]
    }
   ],
   "source": [
    "from rasa_core import utils\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.policies.keras_policy import KerasPolicy\n",
    "from rasa_core.policies.memoization import MemoizationPolicy\n",
    "from rasa_core.policies.sklearn_policy import SklearnPolicy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    utils.configure_colored_logging(loglevel=\"DEBUG\")\n",
    "    \n",
    "    training_data_file = './data/stories.md'\n",
    "    model_path = './models/dialogue'\n",
    "    agent = Agent(\"horoscope_domain.yml\",\n",
    "                 policies=[MemoizationPolicy(), KerasPolicy()])\n",
    "    training_data = agent.load_data(training_data_file)\n",
    "    \n",
    "    agent.train(\n",
    "        training_data,\n",
    "        augmentation_factor=50,\n",
    "        epochs=500, \n",
    "        batch_size=10,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    agent.persist(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/default/horoscopebot\\intent_classifier_tensorflow_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:49:48 INFO     tensorflow  - Restoring parameters from ./models/nlu/default/horoscopebot\\intent_classifier_tensorflow_embedding.ckpt\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Generated trackers will be deduplicated based on their unique last 2 states.\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Number of augmentation rounds is 3\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Starting data generation round 0 ... (with 1 trackers)\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 131.66it/s, # trackers=1]\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Finished phase (5 training samples found).\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Data generation rounds finished.\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Found 0 unused checkpoints\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Starting augmentation round 0 ... (with 5 trackers)\n",
      "Processed Story Blocks: 100%|██████████████████████████████████████████████| 5/5 [00:00<00:00, 90.94it/s, # trackers=4]\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Finished phase (26 training samples found).\n",
      "2020-03-21 23:49:48 DEBUG    rasa_core.training.generator  - Starting augmentation round 1 ... (with 20 trackers)\n",
      "Processed Story Blocks: 100%|██████████████████████████████████████████████| 5/5 [00:00<00:00, 86.26it/s, # trackers=5]\n",
      "2020-03-21 23:49:49 DEBUG    rasa_core.training.generator  - Finished phase (55 training samples found).\n",
      "2020-03-21 23:49:49 DEBUG    rasa_core.training.generator  - Starting augmentation round 2 ... (with 20 trackers)\n",
      "Processed Story Blocks: 100%|██████████████████████████████████████████████| 5/5 [00:00<00:00, 78.17it/s, # trackers=5]\n",
      "2020-03-21 23:49:49 DEBUG    rasa_core.training.generator  - Finished phase (73 training samples found).\n",
      "2020-03-21 23:49:49 DEBUG    rasa_core.training.generator  - Found 73 training trackers.\n",
      "2020-03-21 23:49:49 DEBUG    rasa_core.agent  - Agent trainer got kwargs: {'batch_size': 50, 'epochs': 200, 'max_training_samples': 300}\n",
      "2020-03-21 23:49:49 INFO     rasa_core.featurizers  - Creating states and action examples from collected trackers (by MaxHistoryTrackerFeaturizer(SingleStateFeaturizer))...\n",
      "Processed trackers: 100%|████████████████████████████████████████████████| 73/73 [00:07<00:00,  9.36it/s, # actions=42]\n",
      "2020-03-21 23:49:57 INFO     rasa_core.featurizers  - Created 42 action examples.\n",
      "Processed actions: 42it [00:00, 153.93it/s, # examples=42]\n",
      "2020-03-21 23:49:57 INFO     rasa_core.policies.memoization  - Memorized 42 unique action examples.\n",
      "2020-03-21 23:49:57 INFO     rasa_core.featurizers  - Creating states and action examples from collected trackers (by MaxHistoryTrackerFeaturizer(BinarySingleStateFeaturizer))...\n",
      "Processed trackers: 100%|████████████████████████████████████████████████| 73/73 [00:08<00:00,  8.67it/s, # actions=42]\n",
      "2020-03-21 23:50:05 INFO     rasa_core.featurizers  - Created 42 action examples.\n",
      "2020-03-21 23:50:06 DEBUG    rasa_core.policies.policy  - Limit training data to 300 training samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 2, 22)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                7040      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 297       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 7,337\n",
      "Trainable params: 7,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:50:07 DEBUG    rasa_core.policies.keras_policy  - None\n",
      "2020-03-21 23:50:07 INFO     rasa_core.policies.keras_policy  - Fitting model with 42 total samples and a validation split of 0.0\n",
      "2020-03-21 23:50:07 DEBUG    rasa_core.policies.policy  - Parameters ignored by `model.fit(...)`: {'max_training_samples': 300}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.1915 - acc: 0.2143\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 2.1670 - acc: 0.2857\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 2.1297 - acc: 0.3333\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 2.1324 - acc: 0.3095\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 2.1090 - acc: 0.3571\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 2.1227 - acc: 0.2619\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 2.1062 - acc: 0.3571\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 2.0896 - acc: 0.3333\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 2.0770 - acc: 0.3810\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 2.0724 - acc: 0.4286\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 2.0569 - acc: 0.3571\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 191us/step - loss: 2.0571 - acc: 0.3095\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 2.0541 - acc: 0.4286\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 2.0378 - acc: 0.3571\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 2.0350 - acc: 0.3333\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 2.0397 - acc: 0.3333\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 2.0258 - acc: 0.4524\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 2.0120 - acc: 0.3333\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 2.0133 - acc: 0.3333\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 2.0056 - acc: 0.3333\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 2.0201 - acc: 0.3571\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.9896 - acc: 0.3333\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 238us/step - loss: 1.9732 - acc: 0.4048\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.9796 - acc: 0.3571\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.9551 - acc: 0.4524\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.9302 - acc: 0.4286\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 142us/step - loss: 1.9357 - acc: 0.3810\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.9137 - acc: 0.3810\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.9149 - acc: 0.3810\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.9391 - acc: 0.3810\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.9275 - acc: 0.3333\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.9008 - acc: 0.4048\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.8735 - acc: 0.3810\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.9027 - acc: 0.4048\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.8821 - acc: 0.3810\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.8718 - acc: 0.4048\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.8347 - acc: 0.4762\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.8605 - acc: 0.4048\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.8439 - acc: 0.4048\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.8368 - acc: 0.4048\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.8233 - acc: 0.4286\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.8124 - acc: 0.4048\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.8201 - acc: 0.3810\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.8116 - acc: 0.4286\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.7930 - acc: 0.3810\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.7887 - acc: 0.4048\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.7771 - acc: 0.4524\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.7577 - acc: 0.4286\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.7730 - acc: 0.4762\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.7532 - acc: 0.4286\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.7469 - acc: 0.4524\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.7678 - acc: 0.3571\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.7382 - acc: 0.4048\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.7413 - acc: 0.3571\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.7196 - acc: 0.4286\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.7383 - acc: 0.4048\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.6813 - acc: 0.4286\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.6996 - acc: 0.3810\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.7034 - acc: 0.4524\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.6799 - acc: 0.4762\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.7302 - acc: 0.3571\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.6747 - acc: 0.4048\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.6417 - acc: 0.4762\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.6208 - acc: 0.4286\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.6499 - acc: 0.5000\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.6077 - acc: 0.4524\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.6221 - acc: 0.4048\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.6068 - acc: 0.3571\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.6055 - acc: 0.4762\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.6062 - acc: 0.4286\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.5986 - acc: 0.4286\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.5955 - acc: 0.4286\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.5888 - acc: 0.4286\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.5882 - acc: 0.4524\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 238us/step - loss: 1.5756 - acc: 0.5000\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.5747 - acc: 0.4762\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.5526 - acc: 0.5238\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.5521 - acc: 0.4524\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.5341 - acc: 0.4762\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.5406 - acc: 0.5238\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.5022 - acc: 0.5476\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.5136 - acc: 0.5476\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.5132 - acc: 0.5714\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.4890 - acc: 0.5714\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.4824 - acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.5063 - acc: 0.5952\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.4902 - acc: 0.5714\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.5111 - acc: 0.5952\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.4921 - acc: 0.5000\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 139us/step - loss: 1.4521 - acc: 0.5952\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.4255 - acc: 0.6667\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.4159 - acc: 0.6190\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.4443 - acc: 0.6429\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.4587 - acc: 0.6190\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.4158 - acc: 0.5952\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.4326 - acc: 0.6429\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.4162 - acc: 0.6190\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.3771 - acc: 0.6190\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.3788 - acc: 0.5952\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.3828 - acc: 0.6905\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.3470 - acc: 0.7143\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.3387 - acc: 0.6905\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.3870 - acc: 0.6429\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.3483 - acc: 0.6667\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.3277 - acc: 0.7143\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.3506 - acc: 0.7857\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.3343 - acc: 0.7143\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.2963 - acc: 0.7381\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.3227 - acc: 0.7143\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.2790 - acc: 0.7381\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.2952 - acc: 0.7381\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.2675 - acc: 0.7619\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.2860 - acc: 0.7381\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.2775 - acc: 0.7857\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.2530 - acc: 0.7857\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.2150 - acc: 0.7619\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 262us/step - loss: 1.2332 - acc: 0.7857\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.2422 - acc: 0.6905\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.2530 - acc: 0.7619\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.2276 - acc: 0.7857\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.2236 - acc: 0.8095\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 1.1842 - acc: 0.7857\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.1774 - acc: 0.8333\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.1674 - acc: 0.8095\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.1430 - acc: 0.7619\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.1917 - acc: 0.8095\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 238us/step - loss: 1.1830 - acc: 0.7857\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.1761 - acc: 0.8095\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 238us/step - loss: 1.0893 - acc: 0.8333\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.1445 - acc: 0.8095\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.1267 - acc: 0.8095\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.0858 - acc: 0.8571\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.1296 - acc: 0.8333\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 238us/step - loss: 1.1220 - acc: 0.8571\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 286us/step - loss: 1.0988 - acc: 0.8333\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.0556 - acc: 0.8333\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 1.0918 - acc: 0.7381\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.0921 - acc: 0.8095\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.0205 - acc: 0.8333\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.0272 - acc: 0.8571\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.0446 - acc: 0.7857\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.0068 - acc: 0.8333\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 1.0409 - acc: 0.8333\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 1.0565 - acc: 0.8333\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 1.0638 - acc: 0.7619\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.9590 - acc: 0.8095\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.9928 - acc: 0.8571\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.9829 - acc: 0.8571\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.9535 - acc: 0.8810\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.9337 - acc: 0.8810\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.9462 - acc: 0.8333\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 0.9890 - acc: 0.8095\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.9597 - acc: 0.8095\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.8906 - acc: 0.8810\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 0.9506 - acc: 0.9286\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.8682 - acc: 0.8571\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.8932 - acc: 0.8810\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.8641 - acc: 0.8571\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.9609 - acc: 0.8333\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.8529 - acc: 0.8333\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 0.8311 - acc: 0.8810\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.8224 - acc: 0.8571\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 0.8714 - acc: 0.8095\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.8649 - acc: 0.8571\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.8381 - acc: 0.8333\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.7978 - acc: 0.8571\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.8321 - acc: 0.8810\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.7919 - acc: 0.8810\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.7745 - acc: 0.8810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.8334 - acc: 0.9286\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.8064 - acc: 0.8810\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.7603 - acc: 0.8571\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.7541 - acc: 0.8571\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.7501 - acc: 0.9048\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 0.7560 - acc: 0.8333\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.7089 - acc: 0.9286\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 0.7352 - acc: 0.9048\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 0.7232 - acc: 0.9048\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.7398 - acc: 0.9286\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.6704 - acc: 0.8571\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.6967 - acc: 0.9048\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 0.6601 - acc: 0.9048\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.6566 - acc: 0.8810\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.6642 - acc: 0.9048\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.6346 - acc: 0.9762\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 0.6650 - acc: 0.8810\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 61us/step - loss: 0.6405 - acc: 0.9286\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.6649 - acc: 0.9048\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.6451 - acc: 0.9048\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.5895 - acc: 0.9286\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.6133 - acc: 0.8571\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 143us/step - loss: 0.6063 - acc: 0.9286\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.6365 - acc: 0.9048\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.6026 - acc: 0.9048\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 0.6366 - acc: 0.9048\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.5636 - acc: 0.9286\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 190us/step - loss: 0.5961 - acc: 0.8810\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 119us/step - loss: 0.5728 - acc: 0.9524\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.6154 - acc: 0.8810\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 167us/step - loss: 0.5655 - acc: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:50:17 INFO     rasa_core.policies.keras_policy  - Done fitting keras policy model\n",
      "2020-03-21 23:50:17 INFO     rasa_core.agent  - Model directory ./models/dialog exists and contains old model files. All files will be overwritten.\n",
      "2020-03-21 23:50:18 INFO     rasa_core.agent  - Persisted model to 'C:\\Users\\hung.td170078\\horoscope_bot\\models\\dialog'\n",
      "2020-03-21 23:50:18 INFO     rasa_core.training.online  - Rasa Core server is up and running on http://localhost:5005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot loaded. Type a message and press enter (use '/stop' to exit). \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:50:18 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:50:20 127.0.0.1 - - [2020-03-21 23:50:20] \"GET /domain HTTP/1.1\" 200 1068 0.000000\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"GET /domain HTTP/1.1\" 200 959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next user input:\n",
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:50:49 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:50:51 DEBUG    rasa_core.tracker_store  - Creating a new tracker for id 'default'.\n",
      "2020-03-21 23:50:51 DEBUG    rasa_core.processor  - Received user message 'hi' with intent '{'name': 'greeting', 'confidence': 0.9378805756568909}' and entities '[]'\n",
      "2020-03-21 23:50:51 DEBUG    rasa_core.processor  - Logged UserUtterance - tracker now has 2 events\n",
      "2020-03-21 23:50:51 127.0.0.1 - - [2020-03-21 23:50:51] \"POST /conversations/default/messages HTTP/1.1\" 200 1016 0.170494\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/messages HTTP/1.1\" 200 907\n",
      "2020-03-21 23:50:51 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:50:53 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:50:53 DEBUG    rasa_core.policies.memoization  - Current tracker state [{}, {'prev_action_listen': 1.0, 'intent_greeting': 1.0}]\n",
      "2020-03-21 23:50:53 DEBUG    rasa_core.policies.memoization  - There is a memorised next action '3'\n",
      "2020-03-21 23:50:54 DEBUG    rasa_core.policies.ensemble  - Predicted next action using policy_1_MemoizationPolicy\n",
      "2020-03-21 23:50:54 127.0.0.1 - - [2020-03-21 23:50:54] \"POST /conversations/default/predict HTTP/1.1\" 200 1421 0.437001\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/predict HTTP/1.1\" 200 1311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Chat history:\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\thi\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9378805756568909, 'name': 'greeting'}\n",
      "\n",
      "we currently have slots: DD: None, MM: None, horoscope_sign: None, subscribe: None\n",
      "\n",
      "------\n",
      "The bot wants to [utter_greet] due to the intent. Is this correct?\n",
      "\n",
      "\t1.\tYes\n",
      "\t2.\tNo, intent is right but the action is wrong\n",
      "\t3.\tThe intent is wrong\n",
      "\t0.\tExport current conversations as stories and quit\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:50:57 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:50:59 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:50:59 DEBUG    rasa_core.processor  - Action 'utter_greet' ended with events '[]'\n",
      "2020-03-21 23:50:59 DEBUG    rasa_core.processor  - Bot utterance 'BotUttered(text: Hello! How are you doing today?, data: {\n",
      "  \"elements\": null,\n",
      "  \"buttons\": null,\n",
      "  \"attachment\": null\n",
      "})'\n",
      "2020-03-21 23:50:59 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:50:59 127.0.0.1 - - [2020-03-21 23:50:59] \"POST /conversations/default/execute HTTP/1.1\" 200 1327 0.134920\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/execute HTTP/1.1\" 200 1217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How are you doing today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:50:59 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:01 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:01 DEBUG    rasa_core.policies.memoization  - Current tracker state [{'prev_action_listen': 1.0, 'intent_greeting': 1.0}, {'prev_utter_greet': 1.0, 'intent_greeting': 1.0}]\n",
      "2020-03-21 23:51:01 DEBUG    rasa_core.policies.memoization  - There is a memorised next action '0'\n",
      "2020-03-21 23:51:01 DEBUG    rasa_core.policies.ensemble  - Predicted next action using policy_1_MemoizationPolicy\n",
      "2020-03-21 23:51:01 127.0.0.1 - - [2020-03-21 23:51:01] \"POST /conversations/default/predict HTTP/1.1\" 200 1638 0.143695\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/predict HTTP/1.1\" 200 1528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Chat history:\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\thi\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9378805756568909, 'name': 'greeting'}\n",
      "\n",
      "\tbot did:\tutter_greet\n",
      "\n",
      "we currently have slots: DD: None, MM: None, horoscope_sign: None, subscribe: None\n",
      "\n",
      "------\n",
      "The bot wants to [action_listen]. Is this correct?\n",
      "\n",
      "\t1.\tYes.\n",
      "\t2.\tNo, the action is wrong.\n",
      "\t0.\tExport current conversations as stories and quit\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:51:03 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:05 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:05 DEBUG    rasa_core.processor  - Action 'action_listen' ended with events '[]'\n",
      "2020-03-21 23:51:05 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:05 127.0.0.1 - - [2020-03-21 23:51:05] \"POST /conversations/default/execute HTTP/1.1\" 200 1333 0.096310\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/execute HTTP/1.1\" 200 1223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next user input:\n",
      "what's my horoscope today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:51:26 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:28 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:28 DEBUG    rasa_core.processor  - Received user message 'what's my horoscope today?' with intent '{'name': 'get_horoscope', 'confidence': 0.9410422444343567}' and entities '[]'\n",
      "2020-03-21 23:51:28 DEBUG    rasa_core.processor  - Logged UserUtterance - tracker now has 6 events\n",
      "2020-03-21 23:51:28 127.0.0.1 - - [2020-03-21 23:51:28] \"POST /conversations/default/messages HTTP/1.1\" 200 1704 0.097058\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/messages HTTP/1.1\" 200 1594\n",
      "2020-03-21 23:51:28 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:30 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:30 DEBUG    rasa_core.policies.memoization  - Current tracker state [{'prev_utter_greet': 1.0, 'intent_greeting': 1.0}, {'prev_action_listen': 1.0, 'intent_get_horoscope': 1.0}]\n",
      "2020-03-21 23:51:30 DEBUG    rasa_core.policies.memoization  - There is a memorised next action '4'\n",
      "2020-03-21 23:51:30 DEBUG    rasa_core.policies.ensemble  - Predicted next action using policy_1_MemoizationPolicy\n",
      "2020-03-21 23:51:30 127.0.0.1 - - [2020-03-21 23:51:30] \"POST /conversations/default/predict HTTP/1.1\" 200 2108 0.140182\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/predict HTTP/1.1\" 200 1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Chat history:\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\thi\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9378805756568909, 'name': 'greeting'}\n",
      "\n",
      "\tbot did:\tutter_greet\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\twhat's my horoscope today?\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9410422444343567, 'name': 'get_horoscope'}\n",
      "\n",
      "we currently have slots: DD: None, MM: None, horoscope_sign: None, subscribe: None\n",
      "\n",
      "------\n",
      "The bot wants to [utter_ask_horoscope_sign] due to the intent. Is this correct?\n",
      "\n",
      "\t1.\tYes\n",
      "\t2.\tNo, intent is right but the action is wrong\n",
      "\t3.\tThe intent is wrong\n",
      "\t0.\tExport current conversations as stories and quit\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:51:34 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:36 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:36 DEBUG    rasa_core.processor  - Action 'utter_ask_horoscope_sign' ended with events '[]'\n",
      "2020-03-21 23:51:36 DEBUG    rasa_core.processor  - Bot utterance 'BotUttered(text: What is your horoscope sign?, data: {\n",
      "  \"elements\": null,\n",
      "  \"buttons\": null,\n",
      "  \"attachment\": null\n",
      "})'\n",
      "2020-03-21 23:51:36 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:36 127.0.0.1 - - [2020-03-21 23:51:36] \"POST /conversations/default/execute HTTP/1.1\" 200 2021 0.127169\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/execute HTTP/1.1\" 200 1911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your horoscope sign?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:51:36 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:38 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:38 DEBUG    rasa_core.policies.memoization  - Current tracker state [{'prev_action_listen': 1.0, 'intent_get_horoscope': 1.0}, {'intent_get_horoscope': 1.0, 'prev_utter_ask_horoscope_sign': 1.0}]\n",
      "2020-03-21 23:51:38 DEBUG    rasa_core.policies.memoization  - There is a memorised next action '0'\n",
      "2020-03-21 23:51:39 DEBUG    rasa_core.policies.ensemble  - Predicted next action using policy_1_MemoizationPolicy\n",
      "2020-03-21 23:51:39 127.0.0.1 - - [2020-03-21 23:51:39] \"POST /conversations/default/predict HTTP/1.1\" 200 2335 0.136939\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/predict HTTP/1.1\" 200 2225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Chat history:\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\thi\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9378805756568909, 'name': 'greeting'}\n",
      "\n",
      "\tbot did:\tutter_greet\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\twhat's my horoscope today?\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9410422444343567, 'name': 'get_horoscope'}\n",
      "\n",
      "\tbot did:\tutter_ask_horoscope_sign\n",
      "\n",
      "we currently have slots: DD: None, MM: None, horoscope_sign: None, subscribe: None\n",
      "\n",
      "------\n",
      "The bot wants to [action_listen]. Is this correct?\n",
      "\n",
      "\t1.\tYes.\n",
      "\t2.\tNo, the action is wrong.\n",
      "\t0.\tExport current conversations as stories and quit\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:51:42 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:44 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:44 DEBUG    rasa_core.processor  - Action 'action_listen' ended with events '[]'\n",
      "2020-03-21 23:51:44 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:44 127.0.0.1 - - [2020-03-21 23:51:44] \"POST /conversations/default/execute HTTP/1.1\" 200 2030 0.101884\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/execute HTTP/1.1\" 200 1920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next user input:\n",
      "capricorn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:51:53 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:55 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:55 DEBUG    rasa_core.processor  - Received user message 'capricorn' with intent '{'name': None, 'confidence': 0.0}' and entities '[]'\n",
      "2020-03-21 23:51:55 DEBUG    rasa_core.processor  - Logged UserUtterance - tracker now has 10 events\n",
      "2020-03-21 23:51:55 127.0.0.1 - - [2020-03-21 23:51:55] \"POST /conversations/default/messages HTTP/1.1\" 200 1986 0.103136\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/messages HTTP/1.1\" 200 1876\n",
      "2020-03-21 23:51:55 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:51:57 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:51:57 DEBUG    rasa_core.policies.memoization  - Current tracker state [{'intent_get_horoscope': 1.0, 'prev_utter_ask_horoscope_sign': 1.0}, {'prev_action_listen': 1.0}]\n",
      "2020-03-21 23:51:57 DEBUG    rasa_core.policies.memoization  - There is no memorised next action\n",
      "2020-03-21 23:51:57 DEBUG    rasa_core.policies.ensemble  - Predicted next action using policy_2_KerasPolicy\n",
      "2020-03-21 23:51:57 127.0.0.1 - - [2020-03-21 23:51:57] \"POST /conversations/default/predict HTTP/1.1\" 200 2530 0.118933\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/predict HTTP/1.1\" 200 2420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Chat history:\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\thi\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9378805756568909, 'name': 'greeting'}\n",
      "\n",
      "\tbot did:\tutter_greet\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\twhat's my horoscope today?\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9410422444343567, 'name': 'get_horoscope'}\n",
      "\n",
      "\tbot did:\tutter_ask_horoscope_sign\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\tcapricorn\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.0, 'name': None}\n",
      "\n",
      "we currently have slots: DD: None, MM: None, horoscope_sign: None, subscribe: None\n",
      "\n",
      "------\n",
      "The bot wants to [get_todays_horoscope] due to the intent. Is this correct?\n",
      "\n",
      "\t1.\tYes\n",
      "\t2.\tNo, intent is right but the action is wrong\n",
      "\t3.\tThe intent is wrong\n",
      "\t0.\tExport current conversations as stories and quit\n",
      "3\n",
      "------\n",
      "\n",
      "Message:\n",
      "\n",
      "capricorn\n",
      "User said:\t capricorn\n",
      "What intent is this?\t\n",
      "\t0\tgreeting\n",
      "\t1\tget_horoscope\n",
      "\t2\tsubscription\n",
      "\t3\tdob_intent\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:52:20 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:52:22 127.0.0.1 - - [2020-03-21 23:52:22] \"PUT /conversations/default/tracker/events HTTP/1.1\" 200 2004 0.000000\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"PUT /conversations/default/tracker/events HTTP/1.1\" 200 1894\n",
      "2020-03-21 23:52:22 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:52:24 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:52:24 DEBUG    rasa_core.processor  - Logged UserUtterance - tracker now has 10 events\n",
      "2020-03-21 23:52:24 127.0.0.1 - - [2020-03-21 23:52:24] \"POST /conversations/default/messages HTTP/1.1\" 200 2008 0.079925\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/messages HTTP/1.1\" 200 1898\n",
      "2020-03-21 23:52:24 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:52:26 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:52:26 DEBUG    rasa_core.policies.memoization  - Current tracker state [{'intent_get_horoscope': 1.0, 'prev_utter_ask_horoscope_sign': 1.0}, {'prev_action_listen': 1.0}]\n",
      "2020-03-21 23:52:26 DEBUG    rasa_core.policies.memoization  - There is no memorised next action\n",
      "2020-03-21 23:52:27 DEBUG    rasa_core.policies.ensemble  - Predicted next action using policy_2_KerasPolicy\n",
      "2020-03-21 23:52:27 127.0.0.1 - - [2020-03-21 23:52:27] \"POST /conversations/default/predict HTTP/1.1\" 200 2552 0.141359\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/predict HTTP/1.1\" 200 2442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Chat history:\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\thi\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9378805756568909, 'name': 'greeting'}\n",
      "\n",
      "\tbot did:\tutter_greet\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\twhat's my horoscope today?\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9410422444343567, 'name': 'get_horoscope'}\n",
      "\n",
      "\tbot did:\tutter_ask_horoscope_sign\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\tcapricorn\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 1.0, 'name': 'get_horoscope'}\n",
      "\n",
      "we currently have slots: DD: None, MM: None, horoscope_sign: None, subscribe: None\n",
      "\n",
      "------\n",
      "The bot wants to [get_todays_horoscope] due to the intent. Is this correct?\n",
      "\n",
      "\t1.\tYes\n",
      "\t2.\tNo, intent is right but the action is wrong\n",
      "\t3.\tThe intent is wrong\n",
      "\t0.\tExport current conversations as stories and quit\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:52:43 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:52:45 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:52:45 DEBUG    rasa_core.actions.action  - Calling action endpoint to run action 'get_todays_horoscope'.\n",
      "2020-03-21 23:52:45 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5055\n",
      "2020-03-21 23:52:53 DEBUG    urllib3.connectionpool  - http://localhost:5055 \"POST /webhook HTTP/1.1\" 200 137\n",
      "2020-03-21 23:52:53 DEBUG    rasa_core.processor  - Action 'get_todays_horoscope' ended with events '['SlotSet(key: horoscope_sign, value: None)']'\n",
      "2020-03-21 23:52:53 DEBUG    rasa_core.processor  - Bot utterance 'BotUttered(text: Your today's horoscope:\n",
      "[], data: {\n",
      "  \"elements\": null,\n",
      "  \"buttons\": null,\n",
      "  \"attachment\": null\n",
      "})'\n",
      "2020-03-21 23:52:53 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:52:53 127.0.0.1 - - [2020-03-21 23:52:53] \"POST /conversations/default/execute HTTP/1.1\" 200 2404 8.056355\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/execute HTTP/1.1\" 200 2294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your today's horoscope:\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 23:52:53 DEBUG    urllib3.connectionpool  - Starting new HTTP connection (1): localhost:5005\n",
      "2020-03-21 23:52:55 DEBUG    rasa_core.tracker_store  - Recreating tracker for id 'default'\n",
      "2020-03-21 23:52:55 DEBUG    rasa_core.policies.memoization  - Current tracker state [{'prev_action_listen': 1.0}, {'prev_get_todays_horoscope': 1.0}]\n",
      "2020-03-21 23:52:55 DEBUG    rasa_core.policies.memoization  - There is no memorised next action\n",
      "2020-03-21 23:52:55 DEBUG    rasa_core.policies.ensemble  - Predicted next action using policy_2_KerasPolicy\n",
      "2020-03-21 23:52:55 127.0.0.1 - - [2020-03-21 23:52:55] \"POST /conversations/default/predict HTTP/1.1\" 200 2860 0.093059\n",
      "DEBUG    urllib3.connectionpool  - http://localhost:5005 \"POST /conversations/default/predict HTTP/1.1\" 200 2750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Chat history:\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\thi\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9378805756568909, 'name': 'greeting'}\n",
      "\n",
      "\tbot did:\tutter_greet\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\twhat's my horoscope today?\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 0.9410422444343567, 'name': 'get_horoscope'}\n",
      "\n",
      "\tbot did:\tutter_ask_horoscope_sign\n",
      "\n",
      "\tbot did:\taction_listen\n",
      "\n",
      "\tuser said:\tcapricorn\n",
      "\n",
      "\t\t whose intent is:\t{'confidence': 1.0, 'name': 'get_horoscope'}\n",
      "\n",
      "\tbot did:\tget_todays_horoscope\n",
      "\n",
      "we currently have slots: DD: None, MM: None, horoscope_sign: None, subscribe: None\n",
      "\n",
      "------\n",
      "The bot wants to [action_listen]. Is this correct?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda3\\lib\\site-packages\\gevent\\_ffi\\loop.py\", line 234, in python_check_callback\n",
      "    def python_check_callback(self, watcher_ptr): # pylint:disable=unused-argument\n",
      "KeyboardInterrupt\n",
      "2020-03-21T16:53:08Z\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-943033ed15c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNaturalLanguageInterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlu_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0monline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserve_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\rasa_core\\training\\online.py\u001b[0m in \u001b[0;36mserve_agent\u001b[1;34m(agent, serve_forever, get_next_message)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_app\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mserve_application\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserve_forever\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_next_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\rasa_core\\training\\online.py\u001b[0m in \u001b[0;36mserve_application\u001b[1;34m(app, serve_forever, get_next_message)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mserve_forever\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mhttp_server\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserve_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\gevent\\baseserver.py\u001b[0m in \u001b[0;36mserve_forever\u001b[1;34m(self, stop_timeout)\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mGreenlet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\gevent\\_event.cp36-win_amd64.pyd\u001b[0m in \u001b[0;36mgevent._event.Event.wait\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\gevent\\__abstract_linkable.cp36-win_amd64.pyd\u001b[0m in \u001b[0;36mgevent.__abstract_linkable.AbstractLinkable._wait\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\gevent\\__abstract_linkable.cp36-win_amd64.pyd\u001b[0m in \u001b[0;36mgevent.__abstract_linkable.AbstractLinkable._wait_core\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\gevent\\__abstract_linkable.cp36-win_amd64.pyd\u001b[0m in \u001b[0;36mgevent.__abstract_linkable.AbstractLinkable._wait_core\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\gevent\\__greenlet_primitives.cp36-win_amd64.pyd\u001b[0m in \u001b[0;36mgevent.__greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\gevent\\__greenlet_primitives.cp36-win_amd64.pyd\u001b[0m in \u001b[0;36mgevent.__greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\gevent\\__greenlet_primitives.cp36-win_amd64.pyd\u001b[0m in \u001b[0;36mgevent.__greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc/gevent/__greenlet_primitives.pxd\u001b[0m in \u001b[0;36mgevent.__greenlet_primitives._greenlet_switch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from rasa_core import utils, train\n",
    "from rasa_core.training import online\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def train_agent(interpreter):\n",
    "    return train.train_dialogue_model(domain_file = \"horoscope_domain.yml\",\n",
    "                                   stories_file = \"./data/stories.md\",\n",
    "                                   output_path = \"./models/dialog\",\n",
    "                                   nlu_model_path = interpreter,\n",
    "                                   endpoints = \"endpoints.yml\",\n",
    "                                   max_history = 2,\n",
    "                                   kwargs = {\"batch_size\": 50,\n",
    "                                            \"epochs\": 200,\n",
    "                                            \"max_training_samples\": 300})\n",
    "\n",
    "if __name__  == '__main__':\n",
    "    utils.configure_colored_logging(loglevel = \"DEBUG\")\n",
    "    nlu_model_path = \"./models/nlu/default/horoscopebot\"\n",
    "    interpreter = NaturalLanguageInterpreter.create(nlu_model_path)\n",
    "    agent = train_agent(interpreter)\n",
    "    online.serve_agent(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
